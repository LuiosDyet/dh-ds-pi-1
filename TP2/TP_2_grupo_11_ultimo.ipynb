{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrantes:\n",
    "1. Camila Coltriani\n",
    "2. Luis Dartayet\n",
    "3. Irania Fuentes\n",
    "4. Jonathan Fichelson\n",
    "5. Ornella Cevoli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo práctico 2 : Modelo de regresión lineal del dataset Properatti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este trabajo final es generar y comparar estadísticamente tres modelos de regresión lineal sobre el dataset limpio de Properatti construido en el TP_1; en este, fue planteado la hipótesis que el precio (variable objetivo) de las propiedades iba a estar influenciado principalmente por la superficie y la ubicación (variables predictoras). \n",
    "\n",
    "Con base a esto, se han planteado los siguientes objetivos específicos:\n",
    "- Explorar el dataset limpio con la finalidad de verificar si debe realizarse una ultima limpieza o pueden utilizase los datos directamente;\n",
    "- Realizar una visualización general de las distribuciones y relaciones del dataset con la finalidad de determinar la zona, tipo de inmueble y variables predictoras y objetivo para la realización de los modelos;\n",
    "- Construir modelos de regresión lineal simple y multiple e interpretar sus metricas con la finalidad de identificar el que mejor permita obtener una predicción confiable de la variable objetivo;\n",
    "- Implementar un modelo de regularización con la finalidad de compararlos y evaluar si existe o no problemas de sobreajuste;\n",
    "- Determinar el modelo que más se ajusta al comportamiento de los datos analizados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Las librerías utilizadas en este documento son:\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "from sklearn import metrics\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from matplotlib import gridspec\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de la forma y atributos del dataset\n",
    "data = pd.read_csv(\"./data/data_limpio_gdf.csv\")\n",
    "print(data.shape)\n",
    "print(\"El dataset está compuesto por:\", data.shape[0], \"filas y\",data.shape[1],\"columnas.\")\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descripción de las columnas del dataset limpio:\n",
    "\n",
    "Las columnas que incluye son:\n",
    "\n",
    "● municipio: ubicación del inmueble por su municipio/barrios\n",
    "\n",
    "● provincia: ubicación del inmueble por provincia\n",
    "\n",
    "● lat  ●lon: ubicación de latitud y longitud\n",
    "\n",
    "● superficie_m2_total: superficie total en m² del inmueble\n",
    "\n",
    "● price_usd: Precio en dólares del inmueble\n",
    "\n",
    "● tipo: tipo de inmueble en venta (casa, departamento, ph, tienda)\n",
    "\n",
    "● ambientes_cat: cantidad de ambientes del inmueble (0, 1, 2, 3 , 4 o más)\n",
    "\n",
    "● precio_usd_por_m2: Precio en dólares por metro cuadrado (USD/m²: precio dólares / superficie)\n",
    "\n",
    "● tipo_cat_code: categoría numérica de tipo de inmueble\n",
    "\n",
    "● municipio_cat_code: categoría numérica de municipios\n",
    "\n",
    "● provincia_cat_code: categoría numérica de provincia\n",
    "\n",
    "● tipo_cat_code: categoría numérica de ambientes_cat\n",
    "\n",
    "● geometry: figura geométrica de latitud y la longitud\n",
    "\n",
    "● country_name: nombre del país donde ocurre la operación inmobiliaria\n",
    "\n",
    "● **precio_usd_por_m2_cat: categoría numérica de precio_usd_por_m2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis exploratorio y visualización de correlaciones entre las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Revisamos la presencia de datos NaN\n",
    "data.isna().sum().sort_values()\n",
    "#La columna \"ambientes_cat\" quedó con 1248 registros nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviso donde están ubicados y a que propiedad pertenecen los registros nulos para saber si afectaran escoger un tipo de inmueble y su zona\n",
    "mascara_nulos = data[\"ambientes_cat\"].astype(str) == \"nan\" \n",
    "data_nulos = data[mascara_nulos]\n",
    "data_nulos.loc[:, [\"municipio\", 'tipo', 'ambientes_cat', \"precio_usd\"]].sample(7)\n",
    "#print(data[mascara_nulos].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agrupamos los registros donde hay nulos\n",
    "pd.options.display.max_rows = None\n",
    "data_nulos.groupby([\"tipo\"])[\"municipio\"].value_counts().sort_values(ascending=False)\n",
    "#vemos que los nan están distribuidos equitativamente y no están concentrados en una mismo municipio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Los elimino p\n",
    "data.dropna(subset=['ambientes_cat'], inplace=True)\n",
    "print(data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos algunos outliers\n",
    "\n",
    "data= data[(data[\"precio_usd\"] >100) & (data[\"precio_usd\"]<= 4.500000e+05)]\n",
    "data= data[(data[\"precio_usd_por_m2\"] > 100) & (data[\"precio_usd_por_m2\"]<= 2.500000e+04)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realizamos una descripción estadística del dataset\n",
    "data.describe()\n",
    "#existen datos que no permiten ver los estadísticos ya que hay valores de 0 en sup_m2_total e inf en precio_usd_por_m2: eliminarlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminamos del dataset los registros de sup_m2_total con valores de cero\n",
    "data.drop(data[(data[\"sup_m2_total\"] ==0)].index, inplace=True ,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos la correlación entre las variables \n",
    "data_corr = data.corr()\n",
    "#graficamos\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.heatmap(data_corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "plt.title(\"Correlación entre variables\")\n",
    "plt.show()\n",
    "\n",
    "#puede verse una correlación significativa entre sup_m2_total y precio_usd (0.39)\n",
    "#tipo_cat_code / ambientes_cat_code y  precio_usd (0.30)\n",
    "#precio_usd_por_m2_cat y lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graficamos las provincias y municipios que contengan un valor mínimo de 500 registros por municipio (para una mejor visualización)\n",
    "limite = 500\n",
    "data = data.copy().groupby(['municipio']).filter(lambda grp: grp.shape[0] > limite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig= plt.subplots(figsize=(20,20),constrained_layout=True)\n",
    "grid = gridspec.GridSpec(2, 1, height_ratios=[1, 3])\n",
    "\n",
    "ax1=plt.subplot(grid[0])\n",
    "sns.countplot(data=data,y=\"provincia\",order=data[\"provincia\"].value_counts().index ,ax=ax1,color=\"g\")\n",
    "\n",
    "ax1.set_yticklabels(ax1.get_yticklabels(),fontsize=\"medium\")\n",
    "ax1.set_title(\"Distribucion de registros segun la provincia\", fontsize= 'large')\n",
    "\n",
    "ax2=plt.subplot(grid[1])\n",
    "sns.countplot(data=data,x=\"municipio\",order=data[\"municipio\"].value_counts().index,ax=ax2,color=\"b\")\n",
    "\n",
    "\n",
    "ax2.set_title(\"Distribucion de registros segun los municipios\", fontsize= 'large')\n",
    "ax2.set_xticklabels(ax2.get_xticklabels(),rotation=90,ha=\"right\")\n",
    "plt.xticks(fontsize= 10)\n",
    "plt.yticks(fontsize= 10)\n",
    "ax1.grid()\n",
    "ax2.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La mayor cantidad de registros están Capital Federal para los barrios de Palermo, Belgrano, Caballito..\n",
    "Consideraremos Capital Federal para la evaluación de los modelos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Revisamos la distribución de registros por tipo de inmueble\n",
    "plt.figure(figsize=(5,3))\n",
    "\n",
    "plt.gca().yaxis.set_major_formatter(ScalarFormatter())\n",
    "ax = sns.countplot(data = data, x = \"tipo\")\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=40,ha=\"right\")\n",
    "plt.show()\n",
    "\n",
    "#Apartamentos tiene la mayoría de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideraremos apartamentos para la evaluacion de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Revisamos la ubicacion de los los tipos de inmueble que contienen la mayor cantidad de registros\n",
    "pd.options.display.max_rows = None\n",
    "data.groupby([\"municipio\"])[\"tipo\"].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para determinar en que barrio enfocarnos, generaremos una funcion que correremos para los tres barrios enunciados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos las columnas que vamos a utilizar y sólo las propiedades de tipo apartamento\n",
    "\n",
    "df_0 = data[data['tipo'] == 'apartment']\n",
    "df_0 = data[['municipio', 'sup_m2_total', 'ambientes_cat', 'lat', 'lon', 'precio_usd' ]]\n",
    "df_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraemos un dataframe por cada columna\n",
    "\n",
    "df_0_sup_m2_total = df_0[['sup_m2_total', 'precio_usd', 'municipio']]\n",
    "df_0_ambientes_cat = df_0[['ambientes_cat', 'precio_usd', 'municipio']]\n",
    "df_0_ubica = df_0[['lat', 'lon', 'precio_usd', 'municipio']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armamos la función para las regresiones lineales\n",
    "\n",
    "def regresion_lineal(df_0_lr, target, test_size=0.2, random_state=42):\n",
    "    # Separamos la variable objetivo del resto del dataset\n",
    "    X = df_0_lr.drop(target, axis=1)\n",
    "    y = df_0_lr[target]\n",
    "    \n",
    "    # Dividimos el dataset en train y test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    # Normalizamos los datos\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # Instanciamos el modelo\n",
    "    model = linear_model.LinearRegression()\n",
    "    \n",
    "    # Entrenamos el modelo\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predecimos con el modelo\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculamos el R2\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Imprimimos los resultados\n",
    "    print('R2: ', r2)\n",
    "    print('Intercept: ', model.intercept_)\n",
    "    print('Coeficiente: ', model.coef_[0])\n",
    "    \n",
    "    # Graficamos los resultados\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    plt.scatter(y_test, y_pred)\n",
    "    plt.axline(xy1=(0, 0), slope=1, color='red')\n",
    "    plt.xlabel('Valores reales')\n",
    "    plt.ylabel('Valores predichos')\n",
    "    plt.xlim(0, 1000000)\n",
    "    plt.ylim(0, 1000000)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creamos una mascara para Palermo, Belgrano, Caballito.\n",
    "municipios = np.array(['Palermo', 'Belgrano', 'Caballito'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elegimos estos 3 barrios porque son los que tienen mayor cantidad de registros y mejor R2 inicial en el modelo de regresión lineal simple.\n",
    "> confrontar con el archivo lr-barrios-capital.ipynb donde se corrió el modelo para todos los barrios de capital federal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresión lineal para el precio de las propiedades en función del municipio y la superficie total y guardamos el modelo en un mapa\n",
    "\n",
    "for municipio in municipios:\n",
    "    df_0_municipio =df_0_sup_m2_total[df_0_sup_m2_total['municipio'] == municipio]\n",
    "    if(df_0_municipio.shape[0] > 100):\n",
    "        df_0_municipio = df_0_municipio.drop('municipio', axis=1)\n",
    "        print('Municipio: ', municipio)\n",
    "        regresion_lineal(df_0_municipio, 'precio_usd')\n",
    "        print('----------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlación entre la variables del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analizamos la correlación entre cada una de las variables.\n",
    "figz= plt.figure()\n",
    "mask_cols= [\"tipo\",\"sup_m2_total\",\"precio_usd\",\"precio_usd_por_m2\", \"ambientes_cat\", \"municipio_cat_code\", \"ambientes_cat_code\",\"lat\"]\n",
    "graph=sns.pairplot(data[mask_cols],hue=\"tipo\")\n",
    "graph.fig.set_size_inches(20,10)\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos los siguientes gráficos para visualizar mejor (zoom) las relaciones- En primera medida analizamos metros totales con precio en dolares\n",
    "g = sns.FacetGrid(data, col=\"tipo\")\n",
    "g.map(sns.scatterplot, \"sup_m2_total\", \"precio_usd\", alpha=.5)\n",
    "g.add_legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "g = sns.FacetGrid(data, col=\"tipo\")\n",
    "g.map(sns.scatterplot, \"sup_m2_total\", \"precio_usd_por_m2\", alpha=.5)\n",
    "g.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(data, col=\"tipo\")\n",
    "g.map(sns.scatterplot, \"precio_usd_por_m2\", \"precio_usd\", alpha=.7)\n",
    "g.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(data, col=\"tipo\")\n",
    "g.map(sns.scatterplot, \"municipio_cat_code\", \"precio_usd\", alpha=.7)\n",
    "g.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(data, col=\"tipo\")\n",
    "g.map(sns.scatterplot, \"ambientes_cat_code\", \"precio_usd\", alpha=.7)\n",
    "g.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### la variable target debe tener una distribucion cercana a la normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#de acuerdo con los valores mínimos y máximos realizamos un histograma para ver la distribución de datos de precio_usd\n",
    "data_2= data[(data[\"precio_usd\"] >10000) & (data[\"precio_usd\"]<= 4.500000e+05)]\n",
    "sns.histplot(data_2[\"precio_usd\"], color = \"orange\", bins = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#de acuerdo con los valores mínimos y máximos realizamos un histograma para ver la distribución de datos de superficie total\n",
    "data_2= data[(data[\"sup_m2_total\"] >10) & (data[\"sup_m2_total\"]<= 400)]\n",
    "sns.histplot(data_2[\"sup_m2_total\"], color = \"green\", bins = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2= data[(data[\"precio_usd_por_m2\"] >10) & (data[\"precio_usd_por_m2\"]<= 2.812500e+03)]\n",
    "sns.histplot(data_2[\"precio_usd_por_m2\"], color = \"blue\", bins = 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.boxplot(column= \"precio_usd\", by=\"tipo\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusiones del análisis de variables predictoras y target:\n",
    "- La mayor cantidad de registros están Capital Federal para los barrios de Palermo, Belgrano, Caballito. Seleccionaremos el barrio Caballito porque que tiene una buena cantidad de registros y un buen R2 inicial en el modelo de regresión lineal simple inicial.\n",
    "- Utilizaremos departamentos como el tipo de inmueble a modelar por contener una mayor cantidad de datos\n",
    "- Consideraremos como variables predictoras: Superficie total y precio usd por su alta correlación, y su distribución. Luego evaluaremos el impacto de las variables de ubicación y ambientes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis de regresiones sobre el dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión lineal simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iniciamos con un barrio de Capital Federal con una cantidad de registros mayor a 500 para ver como resulta la regresion utilizando todos los tipos de propiedades de caballito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_Caballito = data[data['municipio'] == 'Caballito']\n",
    "# data_Caballito.to_csv('./data/data_limpio_gdf_caballito.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#leemos el df creado para el barrio de caballito\n",
    "df = pd.read_csv('./data/data_limpio_gdf_caballito.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparamos un modelo de regresión simple sin división de los registros y un modelo con train_split_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repetimos los resultados pero ahora con datos filtrados y mayores métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generamos la regresión simple para el barrio caballito usando como variable predictora la superficie total\n",
    "#sin realizar un train_test_split para ver como dan los resultados\n",
    "X = df[['sup_m2_total']]\n",
    "y = df['precio_usd']\n",
    "\n",
    "# Importamos, Instanciamos, Fiteamos, etc..\n",
    "\n",
    "# Instanciamos el modelo.\n",
    "lm = linear_model.LinearRegression()\n",
    "\n",
    "# Fiteamos el modelo sobre los vectores X e y.\n",
    "model = lm.fit(X, y)\n",
    "#\n",
    "# Guardamos  las predicciones en un nuevo vector que llamaremos predictions.\n",
    "predictions = lm.predict(X)\n",
    "\n",
    "# Imprimimos el intercepto y los coeficientes como atributos del objeto entrenado.\n",
    "print ('Intercepto=', ' ', model.intercept_)\n",
    "print ('b_sup_m2_total=', ' ', model.coef_)\n",
    "# imprimimos la métrica que mide la bondad de ajusto del modelo. En este caso el R2.\n",
    "print ('R2=','', model.score(X, y))\n",
    "print (\"EMC:\", mean_squared_error(y, predictions))\n",
    "print (\"r_EMC:\", np.sqrt(mean_squared_error(y, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Realizamos el modelo de regresión utilizando train_test_split para los mismos datos \n",
    "\n",
    "# # Dividimos el dataset en train y test\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Instanciamos el modelo y lo entrenamos\n",
    "\n",
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(X_train_1, y_train_1)\n",
    "\n",
    "# Guardamos  las predicciones en un nuevo vector que llamaremos predictions.\n",
    "predictions_1 = lr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimimos el intercepto y los coeficientes como atributos del objeto entrenado.\n",
    "print ('Intercepto=', ' ', lr.intercept_)\n",
    "print ('b_sup_m2_total=', ' ', lr.coef_)\n",
    "# imprimimos la métrica que mide la bondad de ajusto del modelo. En este caso el R2.\n",
    "print ('R2_train=', ' ', lr.score(X_train_1, y_train_1))\n",
    "print ('R2_test=', ' ', lr.score(X_test_1, y_test_1))\n",
    "print (\"EMC:\", mean_squared_error(y, predictions_1))\n",
    "print (\"r_EMC:\", np.sqrt(mean_squared_error(y, predictions_1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados del coeficiente en ambos modelos no son tan diferentes, indican que por cada m2 de superficie total el valor del precio en dolares aumenta en 1713 unidades al hacer la separacion de datos y aprox 1693 unid al modelar todos los datos\n",
    "El R2 de entrenamiento disminuye de 0.41 a 0.37 al hacer la separacion de los datos en train_test-_split. \n",
    "Cuando se determina el R2 en los datos no entrenados tenemos una respuesta del 60% de que nuestra variable objetivo es explicada por el modelo\n",
    "En este caso preferimos usar la raiz de EMC ya que los precios estan en el orden de 1e7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos la variable X contra la variable Y, \n",
    "plt.scatter(X, y, s=30, c='black', marker='+', zorder=10)\n",
    "plt.scatter(X, y)\n",
    "plt.xlabel(\"sup_m2_total\")\n",
    "plt.ylabel(\"Valores reales precio_usd\")\n",
    "plt.title('Relación entre sup_m2_total y precio_usd')\n",
    "plt.show()\n",
    "\n",
    "# Graficamos el modelo re regresion del modelo con train_test_split\n",
    "plt.plot(y,y, '-.',c='grey')\n",
    "plt.scatter(predictions, y, s=30, c='r', marker='+', zorder=10)\n",
    "plt.xlabel(\"Predicciones de precio_usd usando sup_m2_total\")\n",
    "plt.ylabel(\"Valores reales precio_usd\")\n",
    "plt.title('Comparación entre el modelo y los valores reales de precio_usd')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El primer gráfico nos permite ver el tipo de relacion entre la variable predictora y la variable objetivo. Se observa que hay cierta correlación entre ellas, pero estan influenciadas por los valores extremos. \n",
    " \n",
    " El segundo gráfico es la comparación entre el valor real de precio en dolares  vs el valor predicho por nuestro modelo. \n",
    " Puede verse que existe la correlación entre las variables pero existe el ruido de los valores extremos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separamos por tipo de inmueble\n",
    "Realizamos un filtro en el tipo de inmueble para ver si existen cambios en el modelo: nos quedamos con departamentos que para el barrio caballito cuenta con mas de 1500 registros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solo para departamentos\n",
    "tipo_dept = [\"apartment\"]\n",
    "df_2 = df[df[\"tipo\"].isin(tipo_dept)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignamos la variable a predecir\n",
    "y_d = df_2['precio_usd']\n",
    "# Asignamos la variable predictora\n",
    "X_d = df_2[['sup_m2_total']]\n",
    "# Dividimos el dataset en train y test\n",
    "\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_d, y_d, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instanciamos el modelo y lo entrenamos\n",
    "\n",
    "lr_d = linear_model.LinearRegression()\n",
    "lr_d.fit(X_train_2, y_train_2)\n",
    "\n",
    "# Guardamos  las predicciones en un nuevo vector que llamaremos predictions.\n",
    "predictions_d = lr_d.predict(X_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimimos el intercepto y los coeficientes como atributos del objeto entrenado.\n",
    "print ('Intercepto=', ' ', lr_d.intercept_)\n",
    "print ('sup_m2_total=', ' ', lr_d.coef_)\n",
    "\n",
    "# imprimos la metrica que mide la bondad de ajusto del modelo. En este caso el R2.\n",
    "\n",
    "print ('R2_train=', ' ', lr_d.score(X_train_2, y_train_2))\n",
    "print ('R2_test=', ' ', lr_d.score(X_test_2, y_test_2))\n",
    "print (\"EMC:\", mean_squared_error(y_d, predictions_d))\n",
    "print (\"r_EMC:\", np.sqrt(mean_squared_error(y_d, predictions_d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos la variable X contra la variable Y\n",
    "plt.scatter(X_d, y_d, s=30, c='black', marker='+', zorder=10)\n",
    "plt.scatter(X_d, y_d)\n",
    "plt.xlabel(\"sup_m2_total\")\n",
    "plt.ylabel(\"Valores reales precio_usd\")\n",
    "plt.title('Relación entre sup_m2_total y precio_usd')\n",
    "plt.show()\n",
    "\n",
    "# Graficamos el modelo\n",
    "plt.plot(y_d,y_d, '-.',c='grey')\n",
    "plt.scatter(predictions_d, y_d, s=30, c='r', marker='+', zorder=10)\n",
    "plt.xlabel(\"Predicciones de precio_usd usando sup_m2_total\")\n",
    "plt.ylabel(\"Valores reales precio_usd\")\n",
    "plt.title('Comparación entre el modelo y los valores reales de precio_usd')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión lineal múltiple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregamos a la correlacion las variables latitud y longitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignamos las variables predictoras\n",
    "\n",
    "X_3 = df_2[['lat', 'lon', 'sup_m2_total']]\n",
    "\n",
    "y_3 = df_2['precio_usd']\n",
    "\n",
    "# Normalizamos los datos\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_3)\n",
    "X_3 = scaler.transform(X_3)\n",
    "\n",
    "# Dividimos en train y test\n",
    "\n",
    "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(X_3, y_3, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instanciamos el modelo y lo entrenamos\n",
    "\n",
    "lr_2= linear_model.LinearRegression()\n",
    "lr_2.fit(X_train_3, y_train_3)\n",
    "\n",
    "# Vemos los coeficientes\n",
    "\n",
    "print('Coeficientes: ', lr_2.coef_)\n",
    "print('Intercepto: ', lr_2.intercept_)\n",
    "print('R2_train: ', r2_score(y_train_3, lr_2.predict(X_train_3)))\n",
    "print('R2_test: ', r2_score(y_test_3, lr_2.predict(X_test_3)))\n",
    "print ('MSE:', metrics.mean_squared_error(y_3, lr_2.predict(X_3)))\n",
    "print ('rMSE:', np.sqrt(metrics.mean_squared_error(y_3, lr_2.predict(X_3))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelamos con statsmodels\n",
    "\n",
    "X_train_sm = sm.add_constant(X_train_3)\n",
    "\n",
    "model = sm.OLS(y_train_3, X_train_sm).fit()\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando la regresión multiple sencilla con la regresión OLS podemos observar como OLS nos permite validar la significancia de los datos obtenidos. Vemos con los p values para las variables latitud y longitud son mayores al nivel de significancia por lo cual estas variables no están explicando o no tiene valor de predicción sobre el valor de nuestra variable objetivo precio en dólares.\n",
    "\n",
    "Al incluir latitud y longitud disminuye el performance del R2 a 0,38 en la regresión multiple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos OLS para ver como resultan las metricas al usar solo la variable superficie total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probamos con regularización ridge\n",
    "\n",
    "lm_ridge = linear_model.RidgeCV(alphas=np.logspace(-6, 6, 13))\n",
    "\n",
    "model_ridge = lm_ridge.fit(X_train_3, y_train_3)\n",
    "\n",
    "print(lm_ridge.alpha_)\n",
    "print(lm_ridge.coef_)\n",
    "print(lm_ridge.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ridge.score(X_test_3, y_test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probamos con regularización lasso\n",
    "\n",
    "lm_lasso = linear_model.LassoCV(alphas=np.logspace(-6, 6, 13), cv=5)\n",
    "\n",
    "model_lasso = lm_lasso.fit(X_train_3, y_train_3)\n",
    "\n",
    "print(lm_lasso.alpha_)\n",
    "print(lm_lasso.coef_)\n",
    "\n",
    "print(lm_lasso.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lasso.score(X_test_3, y_test_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analizaremos el impacto de la variables ambientes en la predicción de la variable precio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos las variables dummies para la variable categórica de ambientes\n",
    "df_0_ambientes_cat = pd.get_dummies(df_0_ambientes_cat, columns=['ambientes_cat'], drop_first=True)\n",
    "print(df_0_ambientes_cat.shape)\n",
    "df_0_ambientes_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = pd.concat([df_0_ambientes_cat,df_2[\"sup_m2_total\"]],axis=1, join='inner')\n",
    "print(df_3.shape)\n",
    "df_3.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignamos las variables predictoras\n",
    "\n",
    "X_amb = df_3[['ambientes_cat_1', 'ambientes_cat_2', 'ambientes_cat_3', 'ambientes_cat_4 o mas','sup_m2_total']]\n",
    "y = df_3['precio_usd']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizamos los datos\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_amb)\n",
    "X_amb = scaler.transform(X_amb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos en train y test\n",
    "\n",
    "X_train_4, X_test_4, y_train_4, y_test_4 = train_test_split(X_amb, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos el modelo y lo entrenamos\n",
    "\n",
    "lr_4 = linear_model.LinearRegression()\n",
    "lr_4.fit(X_train_4, y_train_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos los coeficientes\n",
    "\n",
    "print('Coeficientes: ', lr_4.coef_)\n",
    "print('Intercepto: ', lr_4.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el R2\n",
    "\n",
    "print('R2: ', r2_score(y_test_4, lr_4.predict(X_test_4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelamos con statsmodels\n",
    "\n",
    "X_train_sm_2 = sm.add_constant(X_train_4)\n",
    "model_2 = sm.OLS(y_train_4, X_train_sm_2).fit()\n",
    "\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probamos con regularización ridge\n",
    "\n",
    "lm_ridge_2 = linear_model.RidgeCV(alphas=np.logspace(-6, 6, 13))\n",
    "\n",
    "model_ridge_2 = lm_ridge_2.fit(X_train_4, y_train_4)\n",
    "\n",
    "lm_ridge_2.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ridge.score(X_test_4, y_test_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probamos con regularización lasso\n",
    "\n",
    "lm_lasso_2 = linear_model.LassoCV(alphas=np.logspace(-6, 6, 13), cv=5)\n",
    "\n",
    "model_lasso_2 = lm_lasso_2.fit(X_train_4, y_train_4)\n",
    "\n",
    "lm_lasso_2.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lasso_2.score(X_test_4, y_test_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PENDIENTE- VER SI AJUSTAMOS EL MODELO REDUCIENDO LA CANTIDAD DE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# superficie_min=15\n",
    "# superficie_max=1000\n",
    "\n",
    "# data = data[(data.sup_m2_total <= 1000) & (data.sup_m2_total >= 15)]\n",
    "\n",
    "# data = data[(data.precio_usd <= 4000000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generamos una función que resume los coeficientes, el intercepto y el R2\n",
    "# # \"model\" = objeto con el modelo\n",
    "# # \"X\" = matrix de variables independientes\n",
    "\n",
    "# def sum_mod(lr, X):\n",
    "#     a = pd.DataFrame(lr.coef_ , X_simple.columns.values)\n",
    "#     a = a.append(pd.DataFrame([lr.intercept_, lr.score(X_simple, y)], index=['Intecept','R2']))\n",
    "#     return(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('dh')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "de0c11672bdc465268fe040a07375f6ad60f942d46756d33f7fe9e449a78b4ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
