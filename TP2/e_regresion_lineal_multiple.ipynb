{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Las librerías utilizadas en este documento son:\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "from sklearn import metrics\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from matplotlib import gridspec\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#leemos el df creado para el barrio de caballito\n",
    "df = pd.read_csv('./data/data_limpio_gdf_caballito.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión lineal múltiple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregamos a la correlacion las variables latitud y longitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignamos las variables predictoras\n",
    "\n",
    "X = df[['lat', 'lon', 'sup_m2_total']]\n",
    "\n",
    "y = df['precio_usd']\n",
    "\n",
    "# Normalizamos los datos\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "# Dividimos en train y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instanciamos el modelo y lo entrenamos\n",
    "\n",
    "lr= linear_model.LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Vemos los coeficientes\n",
    "\n",
    "print('Coeficientes: ', lr.coef_)\n",
    "print('Intercepto: ', lr.intercept_)\n",
    "print('R2_train: ', r2_score(y_train, lr.predict(X_train)))\n",
    "print('R2_test: ', r2_score(y_test, lr.predict(X_test)))\n",
    "print ('MSE:', metrics.mean_squared_error(y, lr.predict(X)))\n",
    "rmse_multi = np.sqrt(metrics.mean_squared_error(y, lr.predict(X)))\n",
    "print ('rMSE:', rmse_multi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_simple = 113040.74611014882\n",
    "\n",
    "print('Diferencia porcentual entre el rmse de la regresión simple y la regresión múltiple: ', (rmse_multi - rmse_simple)/rmse_simple*100)\n",
    "print('Diferencia absoluta entre el rmse de la regresión simple y la regresión múltiple: ', rmse_multi - rmse_simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que para la regresión lineal simple, la raíz del error cuadrático medio (RMSE) fue de `r_EMC: 113040.74611014882`, muy similar al RMSE de la regresión lineal múltiple, que es de `r_EMC: 124196.721423661`, una diferencia de `r_EMC: 11155.97531351218` que es del 10% del RMSE de la regresión lineal simple.\n",
    "\n",
    "Esto nos indica que la regresión lineal múltiple no mejora el modelo, por lo que no es necesario agregar más variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos también confirmar que la regresión lineal múltiple no mejora el modelo viendo la no mejora del score de validación cruzada y las correlaciones de las variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation\n",
    "scores = cross_val_score(lr, X, y, cv=5)\n",
    "\n",
    "print('Cross-validated scores:', scores)\n",
    "print('Cross-validated scores mean:', scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observamos las correlaciones entre las variables\n",
    "\n",
    "corr = df[['lat', 'lon', 'sup_m2_total', 'precio_usd']].corr()\n",
    "\n",
    "# Graficamos la matriz de correlaciones\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', linewidths=0.2)\n",
    "plt.title('Matriz de correlaciones', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelamos con statsmodels\n",
    "\n",
    "X_train_sm = sm.add_constant(X_train)\n",
    "\n",
    "model = sm.OLS(y_train, X_train_sm).fit()\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando la regresión multiple sencilla con la regresión OLS podemos observar como OLS nos permite validar la significancia de los datos obtenidos. Vemos con los p values para las variables latitud y longitud son mayores al nivel de significancia por lo cual estas variables no están explicando o no tiene valor de predicción sobre el valor de nuestra variable objetivo precio en dólares.\n",
    "\n",
    "Al incluir latitud y longitud disminuye el performance del R2 a 0,38 en la regresión multiple."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('dh')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "de0c11672bdc465268fe040a07375f6ad60f942d46756d33f7fe9e449a78b4ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
