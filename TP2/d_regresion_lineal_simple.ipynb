{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Las librerías utilizadas en este documento son:\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "from sklearn import metrics\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from matplotlib import gridspec\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión lineal simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para el barrio Caballito de Capital Federal utilizando todos los tipos de propiedades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#leemos el df creado para el barrio de caballito\n",
    "df = pd.read_csv('./data/data_limpio_gdf_caballito.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos a comparar distintos Scores del Modelo utilizando distintos criterios. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos la correlacion entre la variable predictora y objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#representamos los datos de la variable predictora y objetivo para poder intuir si existe una relación y cuantificar dicha relación mediante un coeficiente de correlación.\n",
    "X = df[['sup_m2_total']]\n",
    "y = df['precio_usd']\n",
    "\n",
    "# vemos la correlacion entre las variables\n",
    "corr_test = pearsonr(x = df['sup_m2_total'], y =  df['precio_usd'])\n",
    "\n",
    "#imprimimos el coeficiente de correlacion de pearson y su p value\n",
    "print(\"Estadisticos de la correlación entre superficie y precio\")\n",
    "print(\"Coeficiente de correlación de Pearson: \", corr_test[0])\n",
    "\n",
    "print(\"----------------------------------------------------------\")\n",
    "# Graficamos la variable X contra la variable Y, \n",
    "plt.scatter(X, y, s=30, c='black', marker='+', zorder=10)\n",
    "plt.scatter(X, y)\n",
    "plt.xlabel(\"Sup_m2_total\")\n",
    "plt.ylabel(\"Valores reales Precio\")\n",
    "plt.title('Grafico 1: Relación Superficie y Precio')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El gráfico y la correlación muestran una relación lineal, de intensidad considerable (r = 0.64) . Tiene sentido intentar generar un modelo de regresión lineal con el objetivo de predecir el precio en dolares en función de la superficie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos la regresion simple con los datos totales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generamos la regresión simple para el barrio caballito usando como variable predictora la superficie total\n",
    "#sin realizar una division de los datos para ver como dan los resultados\n",
    "X = df[['sup_m2_total']]\n",
    "y = df['precio_usd']\n",
    "\n",
    "# vemos la correlacion entre las variables\n",
    "corr_test = pearsonr(x = df['sup_m2_total'], y =  df['precio_usd'])\n",
    "# Importamos, Instanciamos, Fiteamos, etc..\n",
    "\n",
    "# Instanciamos el modelo.\n",
    "lm = linear_model.LinearRegression()\n",
    "\n",
    "# Fiteamos el modelo sobre los vectores X e y.\n",
    "model = lm.fit(X, y)\n",
    "#\n",
    "# Guardamos  las predicciones en un nuevo vector que llamaremos predictions.\n",
    "predictions = lm.predict(X)\n",
    "\n",
    "print(\"Estadisticos del modelo sin divivir los datos\")\n",
    "# Imprimimos el intercepto y los coeficientes como atributos del objeto entrenado.\n",
    "print ('Intercepto =', ' ', model.intercept_)\n",
    "print ('b_sup_m2_total=', ' ', model.coef_)\n",
    "# imprimimos la métrica que mide la bondad de ajusto del modelo. En este caso el R2.\n",
    "print ('R2=','', model.score(X, y))\n",
    "print (\"EMC:\", mean_squared_error(y, predictions))\n",
    "print (\"r_EMC:\", np.sqrt(mean_squared_error(y, predictions)))\n",
    "\n",
    "# Graficamos el modelo re regresion del modelo con train_test_split\n",
    "plt.plot(y,y, '-.',c='grey')\n",
    "plt.scatter(predictions, y, s=30, c='r', marker='+', zorder=10)\n",
    "plt.xlabel(\"Predicciones de Precio con Variable Superficie\")\n",
    "plt.ylabel(\"Valores Reales Precio\")\n",
    "plt.title('Grafico 2: Modelo VS Precios Reales')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ahora dividimos en sets de training y testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Realizamos el modelo de regresión utilizando train_test_split para los mismos datos \n",
    "\n",
    "# # Dividimos el dataset en train y test\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Instanciamos el modelo y lo entrenamos\n",
    "\n",
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(X_train_1, y_train_1)\n",
    "\n",
    "# Guardamos  las predicciones en un nuevo vector que llamaremos predictions.\n",
    "predictions_1 = lr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimimos el intercepto y los coeficientes como atributos del objeto entrenado.\n",
    "print(\"Estadisticos del modelo con train_test_split\")\n",
    "print ('Intercepto=', ' ', lr.intercept_)\n",
    "print ('b_sup_m2_total=', ' ', lr.coef_)\n",
    "# imprimimos la métrica que mide la bondad de ajusto del modelo. En este caso el R2.\n",
    "print ('R2_train=', ' ', lr.score(X_train_1, y_train_1))\n",
    "print ('R2_test=', ' ', lr.score(X_test_1, y_test_1))\n",
    "print (\"EMC:\", mean_squared_error(y, predictions_1))\n",
    "print (\"r_EMC:\", np.sqrt(mean_squared_error(y, predictions_1)))\n",
    "\n",
    "# Graficamos el modelo re regresion del modelo con train_test_split\n",
    "plt.plot(y,y, '-.',c='grey')\n",
    "plt.scatter(predictions_1, y, s=30, c='r', marker='+', zorder=10)\n",
    "plt.xlabel(\"Predicciones de Precio con Variable Superficie\")\n",
    "plt.ylabel(\"Valores Reales Precio\")\n",
    "plt.title('Grafico 3: Modelo VS Precios Reales')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resumen de los parametros estadisticos determinados:\n",
    "\n",
    "El valor promedio de precio cuando la superficie total es cero (intercepto) disminuye en el modelo con train-test-split: \n",
    "66921 usd al modelar todos los datos y 55234 usd al hacer la separacion de datos.\n",
    "Al considerar una menor cantidad de datos que modelando a toda \"población\" es razonable.\n",
    "\n",
    "El efecto promedio que tiene sobre precio usd el incremento en una unidad de superficie total aumenta en el modelo con separacion de datos: 1875 unidades al hacer la separacion de datos y aprox 1694 unid al modelar todos los datos\n",
    "\n",
    "El R2 es la respuesta de que nuestra variable objetivo es explicada por el modelo, por lo que tenemos mejores resultados al testear con una menor cantidad de datos. \n",
    "\n",
    "    El R2 de entrenamiento disminuye de 0.41 a 0.39 al hacer la separacion de los datos en train_test_split. \n",
    "\n",
    "    El R2 para el test es de 0.43\n",
    "\n",
    "El error (r_EMC) de test es de 124250. Las predicciones del modelo final se alejan en promedio 124250 unidades del valor real.\n",
    "\n",
    "En resumen: \n",
    "Al separar los datos estamos tomando muestras sobre nuestra poblacion muestral en el cual la muestra evaluada puede dar considerablemente diferente. \n",
    "\n",
    "    Al realizar la prueba test se observa que el modelo es capaz de explicar el 43% de la variabilidad observada en la variable precio en usd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separamos por tipo de inmueble\n",
    "Realizamos un filtro en el tipo de inmueble para ver si existen cambios en el modelo: nos quedamos con departamentos que para el barrio caballito cuenta con mas de 1500 registros. Existe un motivo adicional, sospechamos que la superficie total no sea buen predictor para casas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solo para departamentos\n",
    "tipo_dept = [\"apartment\"]\n",
    "df_deptos = df[df[\"tipo\"].isin(tipo_dept)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignamos la variable a predecir\n",
    "y_d = df_deptos['precio_usd']\n",
    "# Asignamos la variable predictora\n",
    "X_d = df_deptos[['sup_m2_total']]\n",
    "# Dividimos el dataset en train y test\n",
    "\n",
    "X_train_d, X_test_d, y_train_d, y_test_d = train_test_split(X_d, y_d, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instanciamos el modelo y lo entrenamos\n",
    "\n",
    "lr_d = linear_model.LinearRegression()\n",
    "lr_d.fit(X_train_d, y_train_d)\n",
    "\n",
    "# Guardamos  las predicciones en un nuevo vector que llamaremos predictions.\n",
    "predictions_d = lr_d.predict(X_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimimos el intercepto y los coeficientes como atributos del objeto entrenado.\n",
    "print ('Intercepto=', ' ', lr_d.intercept_)\n",
    "print ('sup_m2_total=', ' ', lr_d.coef_)\n",
    "\n",
    "# imprimos la metrica que mide la bondad de ajusto del modelo. En este caso el R2.\n",
    "\n",
    "print ('R2_train=', ' ', lr_d.score(X_train_d, y_train_d))\n",
    "print ('R2_test=', ' ', lr_d.score(X_test_d, y_test_d))\n",
    "print (\"EMC:\", mean_squared_error(y_d, predictions_d))\n",
    "print (\"r_EMC:\", np.sqrt(mean_squared_error(y_d, predictions_d)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pareciera ser que utilizando sólo departamentos el modelo empeora un poco lo cuál llama la atención considerablemente. \n",
    "¿Puede ser que justo sea por cómo fue hecha la distribución de los datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos la validación cruzada con 5 folds de la data con todos los tipos de propiedades.\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "\n",
    "# Imprimimos los scores de cada fold.\n",
    "\n",
    "print ('Cross-validated scores:', scores)\n",
    "\n",
    "# Imprimimos el promedio de los scores.\n",
    "\n",
    "print ('Promedio de los scores:', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos la validación cruzada con 5 folds de la data con departamentos.\n",
    "\n",
    "scores_d = cross_val_score(model, X_d, y_d, cv=5)\n",
    "\n",
    "# Imprimimos los scores de cada fold.\n",
    "\n",
    "print ('Cross-validated scores:', scores_d)\n",
    "\n",
    "# Imprimimos el promedio de los scores.\n",
    "\n",
    "print ('Promedio de los scores:', scores_d.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos el promedio de los scores de cada tipo de propiedad.\n",
    "\n",
    "plt.plot(range(5),scores_d.mean()*np.ones(5),c='r',label='Departamentos')\n",
    "plt.plot(range(5),scores.mean()*np.ones(5), c='b',label='Todos los tipos')\n",
    "plt.bar(range(5), scores_d, align='center', alpha=0.5, color='r')\n",
    "plt.bar(range(5), scores, align='center', alpha=0.5, color='b')\n",
    "plt.plot(scores_d.mean(), 'r')\n",
    "plt.plot(scores.mean(), 'r')\n",
    "plt.xlabel('Folds')\n",
    "plt.ylabel('R2')\n",
    "plt.title('R2 por fold')\n",
    "plt.legend(['Departamentos', 'Todos los tipos'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con cross validation podemos confirmar que efectivamente el modelo mejora al utilizar sólo departamentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos la variable X contra la variable Y\n",
    "plt.scatter(X_d, y_d, s=30, c='black', marker='+', zorder=10)\n",
    "plt.scatter(X_d, y_d)\n",
    "plt.xlabel(\"Superficie m_2\")\n",
    "plt.ylabel(\"Precios Reales\")\n",
    "plt.title('Relación Superficie y Precio')\n",
    "plt.show()\n",
    "\n",
    "# Graficamos el modelo\n",
    "plt.plot(y_d,y_d, '-.',c='grey')\n",
    "plt.scatter(predictions_d, y_d, s=30, c='r', marker='+', zorder=10)\n",
    "plt.xlabel(\"Predicciones de Precio con Variable Superficie\")\n",
    "plt.ylabel(\"Precios Reales\")\n",
    "plt.title('Modelo vs Precios Reales')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('DH')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fa08644e93f5ad6b3c1e930965e944c16707fd43381b34471e0217a3cc73ebe0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
