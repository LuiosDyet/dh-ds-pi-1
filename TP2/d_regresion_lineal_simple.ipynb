{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Las librerías utilizadas en este documento son:\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "from sklearn import metrics\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from matplotlib import gridspec\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión lineal simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iniciamos con un barrio de Capital Federal con una cantidad de registros mayor a 500 para ver como resulta la regresion utilizando todos los tipos de propiedades de caballito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#leemos el df creado para el barrio de caballito\n",
    "df = pd.read_csv('./data/data_limpio_gdf_caballito.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos a Comparar distintos Scores del Modelo utilizando distintos criterios. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generamos la regresión simple para el barrio caballito usando como variable predictora la superficie total\n",
    "#sin realizar un train_test_split para ver como dan los resultados\n",
    "X = df[['sup_m2_total']]\n",
    "y = df['precio_usd']\n",
    "\n",
    "# Importamos, Instanciamos, Fiteamos, etc..\n",
    "\n",
    "# Instanciamos el modelo.\n",
    "lm = linear_model.LinearRegression()\n",
    "\n",
    "# Fiteamos el modelo sobre los vectores X e y.\n",
    "model = lm.fit(X, y)\n",
    "#\n",
    "# Guardamos  las predicciones en un nuevo vector que llamaremos predictions.\n",
    "predictions = lm.predict(X)\n",
    "\n",
    "# Imprimimos el intercepto y los coeficientes como atributos del objeto entrenado.\n",
    "print ('Intercepto=', ' ', model.intercept_)\n",
    "print ('b_sup_m2_total=', ' ', model.coef_)\n",
    "# imprimimos la métrica que mide la bondad de ajusto del modelo. En este caso el R2.\n",
    "print ('R2=','', model.score(X, y))\n",
    "print (\"EMC:\", mean_squared_error(y, predictions))\n",
    "print (\"r_EMC:\", np.sqrt(mean_squared_error(y, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ahora dividimos en sets de training y testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Realizamos el modelo de regresión utilizando train_test_split para los mismos datos \n",
    "\n",
    "# # Dividimos el dataset en train y test\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Instanciamos el modelo y lo entrenamos\n",
    "\n",
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(X_train_1, y_train_1)\n",
    "\n",
    "# Guardamos  las predicciones en un nuevo vector que llamaremos predictions.\n",
    "predictions_1 = lr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimimos el intercepto y los coeficientes como atributos del objeto entrenado.\n",
    "print ('Intercepto=', ' ', lr.intercept_)\n",
    "print ('b_sup_m2_total=', ' ', lr.coef_)\n",
    "# imprimimos la métrica que mide la bondad de ajusto del modelo. En este caso el R2.\n",
    "print ('R2_train=', ' ', lr.score(X_train_1, y_train_1))\n",
    "print ('R2_test=', ' ', lr.score(X_test_1, y_test_1))\n",
    "print (\"EMC:\", mean_squared_error(y, predictions_1))\n",
    "print (\"r_EMC:\", np.sqrt(mean_squared_error(y, predictions_1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados del coeficiente en ambos modelos no son tan diferentes, indican que por cada m2 de superficie total el valor del precio en dolares aumenta en 1713 unidades al hacer la separacion de datos y aprox 1693 unid al modelar todos los datos\n",
    "El R2 de entrenamiento disminuye de 0.41 a 0.37 al hacer la separacion de los datos en train_test-_split. \n",
    "Cuando se determina el R2 en los datos no entrenados tenemos una respuesta del 60% de que nuestra variable objetivo es explicada por el modelo\n",
    "En este caso preferimos usar la raiz de EMC ya que comparte la escala con la variable original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos la variable X contra la variable Y, \n",
    "plt.scatter(X, y, s=30, c='black', marker='+', zorder=10)\n",
    "plt.scatter(X, y)\n",
    "plt.xlabel(\"Sup_m2_total\")\n",
    "plt.ylabel(\"Valores reales Precio\")\n",
    "plt.title('Relación Superficie y Precio')\n",
    "plt.show()\n",
    "\n",
    "# Graficamos el modelo re regresion del modelo con train_test_split\n",
    "plt.plot(y,y, '-.',c='grey')\n",
    "plt.scatter(predictions, y, s=30, c='r', marker='+', zorder=10)\n",
    "plt.xlabel(\"Predicciones de Precio con Variable Superficie\")\n",
    "plt.ylabel(\"Valores Reales Precio\")\n",
    "plt.title('Modelo VS Precios Reales')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El primer gráfico nos permite ver el tipo de relacion entre la variable predictora y la variable objetivo. Se observa que hay cierta correlación entre ellas, pero estan influenciadas por los valores extremos. \n",
    " \n",
    " El segundo gráfico es la comparación entre el valor real de precio en dolares  vs el valor predicho por nuestro modelo. \n",
    " Puede verse que existe la correlación entre las variables pero existe el ruido de los valores extremos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separamos por tipo de inmueble\n",
    "Realizamos un filtro en el tipo de inmueble para ver si existen cambios en el modelo: nos quedamos con departamentos que para el barrio caballito cuenta con mas de 1500 registros. Existe un motivo adicional, sospechamos que la superficie total no sea buen predictor para casas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solo para departamentos\n",
    "tipo_dept = [\"apartment\"]\n",
    "df_deptos = df[df[\"tipo\"].isin(tipo_dept)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignamos la variable a predecir\n",
    "y_d = df_deptos['precio_usd']\n",
    "# Asignamos la variable predictora\n",
    "X_d = df_deptos[['sup_m2_total']]\n",
    "# Dividimos el dataset en train y test\n",
    "\n",
    "X_train_d, X_test_d, y_train_d, y_test_d = train_test_split(X_d, y_d, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instanciamos el modelo y lo entrenamos\n",
    "\n",
    "lr_d = linear_model.LinearRegression()\n",
    "lr_d.fit(X_train_d, y_train_d)\n",
    "\n",
    "# Guardamos  las predicciones en un nuevo vector que llamaremos predictions.\n",
    "predictions_d = lr_d.predict(X_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimimos el intercepto y los coeficientes como atributos del objeto entrenado.\n",
    "print ('Intercepto=', ' ', lr_d.intercept_)\n",
    "print ('sup_m2_total=', ' ', lr_d.coef_)\n",
    "\n",
    "# imprimos la metrica que mide la bondad de ajusto del modelo. En este caso el R2.\n",
    "\n",
    "print ('R2_train=', ' ', lr_d.score(X_train_d, y_train_d))\n",
    "print ('R2_test=', ' ', lr_d.score(X_test_d, y_test_d))\n",
    "print (\"EMC:\", mean_squared_error(y_d, predictions_d))\n",
    "print (\"r_EMC:\", np.sqrt(mean_squared_error(y_d, predictions_d)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pareciera ser que utilizando sólo departamentos el modelo empeora un poco lo cuál llama la atención considerablemente. \n",
    "¿Puede ser que justo sea por cómo fue hecha la distribución de los datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos la validación cruzada con 5 folds de la data con todos los tipos de propiedades.\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "\n",
    "# Imprimimos los scores de cada fold.\n",
    "\n",
    "print ('Cross-validated scores:', scores)\n",
    "\n",
    "# Imprimimos el promedio de los scores.\n",
    "\n",
    "print ('Promedio de los scores:', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos la validación cruzada con 5 folds de la data con departamentos.\n",
    "\n",
    "scores_d = cross_val_score(model, X_d, y_d, cv=5)\n",
    "\n",
    "# Imprimimos los scores de cada fold.\n",
    "\n",
    "print ('Cross-validated scores:', scores_d)\n",
    "\n",
    "# Imprimimos el promedio de los scores.\n",
    "\n",
    "print ('Promedio de los scores:', scores_d.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos el promedio de los scores de cada tipo de propiedad.\n",
    "\n",
    "plt.plot(range(5),scores_d.mean()*np.ones(5),c='r',label='Departamentos')\n",
    "plt.plot(range(5),scores.mean()*np.ones(5), c='b',label='Todos los tipos')\n",
    "plt.bar(range(5), scores_d, align='center', alpha=0.5, color='r')\n",
    "plt.bar(range(5), scores, align='center', alpha=0.5, color='b')\n",
    "plt.plot(scores_d.mean(), 'r')\n",
    "plt.plot(scores.mean(), 'r')\n",
    "plt.xlabel('Folds')\n",
    "plt.ylabel('R2')\n",
    "plt.title('R2 por fold')\n",
    "plt.legend(['Departamentos', 'Todos los tipos'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con cross validation podemos confirmar que efectivamente el modelo mejora al utilizar sólo departamentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos la variable X contra la variable Y\n",
    "plt.scatter(X_d, y_d, s=30, c='black', marker='+', zorder=10)\n",
    "plt.scatter(X_d, y_d)\n",
    "plt.xlabel(\"Superficie m_2\")\n",
    "plt.ylabel(\"Precios Reales\")\n",
    "plt.title('Relación Superficie y Precio')\n",
    "plt.show()\n",
    "\n",
    "# Graficamos el modelo\n",
    "plt.plot(y_d,y_d, '-.',c='grey')\n",
    "plt.scatter(predictions_d, y_d, s=30, c='r', marker='+', zorder=10)\n",
    "plt.xlabel(\"Predicciones de Precio con Variable Superficie\")\n",
    "plt.ylabel(\"Precios Reales\")\n",
    "plt.title('Modelo vs Precios Reales')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('dhdsblend2021')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e3992eb757f67fa58e1b7420bd255465c6460a1b97046e2d656cf828845056f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
