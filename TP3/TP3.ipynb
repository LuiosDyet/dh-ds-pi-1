{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Introducción e hipótesis"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "El objetivo es predecir si un cliente se dará de baja o no de la plataforma."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Las librerías utilizadas en este documento son:\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.preprocessing import OneHotEncoder \n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.model_selection import cross_val_score, KFold\n",
                "from sklearn.preprocessing import binarize\n",
                "\n",
                "%matplotlib inline\n",
                "from matplotlib import pyplot as plt\n",
                "from matplotlib.ticker import ScalarFormatter\n",
                "from matplotlib import gridspec\n",
                "import seaborn as sns\n",
                "sns.set()\n",
                "\n",
                "import statsmodels.api as sm\n",
                "from sklearn.naive_bayes import GaussianNB\n",
                "from sklearn.neighbors import KNeighborsClassifier\n",
                "\n",
                "from sklearn import metrics\n",
                "from sklearn.metrics import mean_squared_error, r2_score\n",
                "from sklearn.metrics import confusion_matrix\n",
                "from sklearn.metrics import roc_curve\n",
                "from sklearn.metrics import roc_auc_score\n",
                "from sklearn.metrics import classification_report\n",
                "from sklearn.metrics import accuracy_score\n",
                "from sklearn.metrics import precision_score\n",
                "from sklearn.metrics import recall_score\n",
                "from sklearn.metrics import f1_score\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Carga de datos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data  = pd.read_csv('./data/Datos ML 2021 Q2.csv', sep=';')\n",
                "print(\"El dataset tiene {} filas y {} columnas\".format(data.shape[0], data.shape[1]))\n",
                "data.head()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Descripción del dataset"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### El dataset tiene las siguientes columnas:\n",
                "\n",
                "- CustomerID: ID del cliente\n",
                "- Churn: Columna que indica si el cliente dejó de usar la plataforma o no. 1 es que se da de baja.\n",
                "- CustomerTenure: Es el tiempo transcurrido desde el inicio de la relación con el cliente (en meses)\n",
                "- MainDeviceLogin: Dispositivo principal que utiliza el cliente para acceder a la plataforma\n",
                "- CityTier: Indicador del nivel de desarrollo de la ciudad donde vive el cliente\n",
                "- WarehouseToHome: Distancia desde el centro de distribución a la vivienda del cliente (en km)\n",
                "- MainPaymentMode: Método de pago más utilizado por el cliente\n",
                "- Gender: Género del cliente\n",
                "- HourSpendOnApp: Número de horas que el cliente ha pasado en la plataforma\n",
                "- DeviceRegistered: Número de dispositivos en los que el cliente ha accedido a la plataforma\n",
                "- PrefCategory: Categoría más común de las compras del cliente en el último mes\n",
                "- SatisfactionScore: Nivel de satisfacción del cliente con el servicio\n",
                "- MaritalStatus: Estado civil del cliente\n",
                "- NumberOfAddress: Número de direcciones diferentes registradas por el cliente\n",
                "- Complain: Si ha realizado reclamos\n",
                "- OrderAmountHikeFromlastYear: Incremento porcentual en la cantidad de compras con respecto al año anterior\n",
                "- CouponUsed: Número de cupones usados en el último mes\n",
                "- OrderCount: Número de compras realizadas en el último mes\n",
                "- DaySinceLastOrder: Cantidad de días desde la última compra\n",
                "- CashbackAmount: Promedio de reembolsos pedidos en el último mes"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Exploración de datos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data.describe()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "display(data['Churn'].value_counts())\n",
                "display(data['Churn'].value_counts(normalize=True))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Analicemos las columnas sospechosas"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "##Se consideran columnas con valores sospechosos aquellas cuya máxima que se encuentran \n",
                "# por encima de 3 desviaciones estándar de la media. \n",
                "\n",
                "std_limit = 3\n",
                "\n",
                "##Por la naturaleza de las variables, se considera que los valores sospechosos son aquellos \n",
                "# que se encuentran por encima y no los inferiores.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Columnas sospechosas\n",
                "\n",
                "suspicious_columns = []\n",
                "\n",
                "for col in data.columns:\n",
                "    if(data[col].dtype == 'object'):\n",
                "        continue\n",
                "    mean = data[col].mean()\n",
                "    std = data[col].std()\n",
                "    max = data[col].max()\n",
                "    if(max > mean + std_limit*std):\n",
                "        suspicious_columns.append(data[col].name)\n",
                "        \n",
                "\n",
                "suspicious_columns\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "suspicious_rows_arr = []\n",
                "\n",
                "def investigate_suspicious_column(data, column, watch_outliers=True):\n",
                "    fig, ax = plt.subplots(1,2, figsize=(15,5))\n",
                "    plt.suptitle(column)\n",
                "    sns.histplot(data[column], ax=ax[0])\n",
                "    sns.boxplot(data=data[column], ax=ax[1], orient='h')\n",
                "\n",
                "    plt.show()\n",
                "\n",
                "    if(watch_outliers):\n",
                "        mean = data[column].mean()\n",
                "        std = data[column].std()\n",
                "        max = data[column].max()\n",
                "\n",
                "        suspicious_rows = data[data[column] > mean + std_limit*std]\n",
                "        suspicious_rows_arr.append(suspicious_rows)\n",
                "        display(\"Hay {} filas sospechosas\".format(suspicious_rows.shape[0]))\n",
                "        display(suspicious_rows)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for col in suspicious_columns:\n",
                "    investigate_suspicious_column(data, col)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Total de filas sospechosas\n",
                "\n",
                "print(\"Hay {} filas sospechosas\".format(sum([suspicious_rows.shape[0] for suspicious_rows in suspicious_rows_arr])))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Filas sospechosas agrupadas por columna churn\n",
                "\n",
                "suspicious_rows = pd.concat(suspicious_rows_arr)\n",
                "display(suspicious_rows['Churn'].value_counts())\n",
                "display(suspicious_rows['Churn'].value_counts(normalize=True))\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Observamos que la distribución de la variable Churn entre los valores extremos es similar, por lo que no parece haber una relación entre la variable y la variable objetivo.\n",
                "\n",
                "Por otro lado, haciendo una observación pormenorizada, creemos que en los casos de las columnas `CouponUsed`, `OrderCount` y `DaySinceLastOrder`  y `CashbackAmount` parecen ser valores lógicos, aún tratándose de valores extremos por lo que no las eliminaremos."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "suspicious_columns"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "suspicious_columns.remove('CouponUsed')\n",
                "suspicious_columns.remove('OrderCount')\n",
                "suspicious_columns.remove('DaySinceLastOrder')\n",
                "suspicious_columns.remove('CashbackAmount')\n",
                "\n",
                "suspicious_columns"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Limpiemos las filas sospechosas"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def remove_outliers(data, column):\n",
                "    mean = data[column].mean()\n",
                "    std = data[column].std()\n",
                "    max = data[column].max()\n",
                "    return data[data[column] <= mean + std_limit*std]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for col in suspicious_columns:\n",
                "    data = remove_outliers(data, col)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Veamos el resultado"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for col in suspicious_columns:\n",
                "    investigate_suspicious_column(data, col, False)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Visualización de datos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(nrows=7, ncols=3, figsize=(32,32))\n",
                "fig.suptitle('Histogramas normalizados')\n",
                "for c, ax in zip(data.columns, axes.flatten()):\n",
                "    sns.histplot(data = data.loc[data['Churn']==0, c].dropna(), stat = 'density', ax = ax, kde = False )\n",
                "    sns.histplot(data = data.loc[data['Churn']==1, c].dropna(), stat = 'density', kde=False, ax=ax, color = 'orange')\n",
                "    ax.legend(['Churn = 0', 'Churn = 1'])"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Podemos inferir que las variables que tendrán una significancia en establecer el valor del churn son aquellas en las cuales podemos observar diferencias en la distribución de los valores de churn.\n",
                "\n",
                "Por lo tanto podemos descartar las variables que no presentan diferencias en la distribución de los valores de churn."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Variables a eliminar\n",
                "\n",
                "columns_to_eliminate = ['CustomerID', 'Gender', 'NumberOfAddress']\n",
                "\n",
                "data = data.drop(columns_to_eliminate, axis=1)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Veamos la correlación entre las variables"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(20,10))\n",
                "sns.heatmap(data.corr(), annot=True, vmin=-1, cmap='Blues')"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Limpieza de datos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Veamos cuantos valores nulos hay en cada columna\n",
                "\n",
                "data.isna().sum()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Los eliminamos\n",
                "\n",
                "data.dropna(inplace=True)\n",
                "\n",
                "display(data.isna().sum())\n",
                "\n",
                "print(\"El dataset limpio tiene {} filas y {} columnas\".format(data.shape[0], data.shape[1]))\n",
                "\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Observemos la distribución de los valores de churn"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "display(data['Churn'].value_counts())\n",
                "display(data['Churn'].value_counts(normalize=True))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "El dataset está desbalanceado, por lo que se deberá tener en cuenta al momento de entrenar los modelos.\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Separación de datos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X = data.drop(['Churn'], axis=1)\n",
                "y = data['Churn']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
                "print(X_train.shape)\n",
                "print(X_test.shape)\n",
                "print(y_train.shape)\n",
                "print(y_test.shape)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Preparación de datos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "categorical_columns = [col for col in data.columns if data[col].dtypes == 'object']\n",
                "\n",
                "categorical_columns"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "numerical_columns = [col for col in data.columns if data[col].dtypes != 'object']\n",
                "\n",
                "numerical_columns"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# DeviceRegistered es una variable categórica \n",
                "\n",
                "numerical_columns.remove('DeviceRegistered')\n",
                "categorical_columns.append('DeviceRegistered')\n",
                "\n",
                "# La transformamos a categórica\n",
                "\n",
                "X_train['DeviceRegistered'] = X_train['DeviceRegistered'].astype('object')\n",
                "X_test['DeviceRegistered'] = X_test['DeviceRegistered'].astype('object')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Complain es una variable categórica binaria \n",
                "\n",
                "numerical_columns.remove('Complain')\n",
                "categorical_columns.append('Complain')\n",
                "\n",
                "# La transformamos a categórica\n",
                "\n",
                "X_train['Complain'] = X_train['Complain'].astype('object')\n",
                "X_test['Complain'] = X_test['Complain'].astype('object')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "display('categorical_columns',categorical_columns)\n",
                "display('numerical_columns',numerical_columns)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Variables categóricas"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "encoder_categories = []\n",
                "\n",
                "X_categorical_columns = [x for x in categorical_columns]\n",
                "\n",
                "for col in X_categorical_columns:    \n",
                "    col_categories = data[col].unique()\n",
                "    encoder_categories.append(col_categories)\n",
                "\n",
                "encoder_categories"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "encoder = OneHotEncoder(categories = encoder_categories, sparse=False, drop='first')\n",
                "\n",
                "encoder = encoder.fit(X_train[X_categorical_columns])\n",
                "\n",
                "X_train_encoded = encoder.transform(X_train[X_categorical_columns])\n",
                "X_train_categorical = pd.DataFrame(X_train_encoded, columns = encoder.get_feature_names_out(X_categorical_columns))\n",
                "\n",
                "X_test_encoded = encoder.transform(X_test[X_categorical_columns])\n",
                "X_test_categorical = pd.DataFrame(X_test_encoded, columns = encoder.get_feature_names_out(X_categorical_columns))\n",
                "X_test_categorical.head()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Variables numéricas"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train_numerical = X_train.drop(X_categorical_columns, axis=1)\n",
                "X_test_numerical = X_test.drop(X_categorical_columns, axis=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "scaler = StandardScaler()\n",
                "\n",
                "X_train_scaled = scaler.fit_transform(X_train_numerical)\n",
                "X_train_numerical = pd.DataFrame(X_train_scaled, columns = X_train_numerical.columns)\n",
                "\n",
                "X_test_scaled = scaler.transform(X_test_numerical)\n",
                "X_test_numerical = pd.DataFrame(X_test_scaled, columns = X_test_numerical.columns)\n",
                "X_test_numerical.head()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Unimos las variables numéricas y categóricas"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train = pd.concat([X_train_categorical, X_train_numerical], axis=1)\n",
                "X_test = pd.concat([X_test_categorical, X_test_numerical], axis=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(X_train.shape)\n",
                "print(X_test.shape)\n",
                "print(y_train.shape)\n",
                "print(y_test.shape)\n",
                "\n",
                "X_train.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# null accuracy - accuracy predicha por un modelo que predice siempre la clase mayoritaria\n",
                "\n",
                "total = y_test.shape[0]\n",
                "tn = y_test.value_counts()[0]\n",
                "fn = y_test.value_counts()[1]\n",
                "tp = 0\n",
                "fp = 0\n",
                "null_accuracy = (tp + tn)/(tp + tn + fp + fn)\n",
                "print(\"TN: {}\".format(tn))\n",
                "print(\"FN: {}\".format(fn))\n",
                "print(\"Null accuracy: {}\".format(null_accuracy))\n",
                "\n",
                "# También podemos calcularlo con la siguiente función\n",
                "# y_test.value_counts(normalize=True).max()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Utils para modelos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_confusion_matrix(y_test, y_pred):\n",
                "    \n",
                "    conf_mat = confusion_matrix(y_test, y_pred)\n",
                "    conf_mat_df = pd.DataFrame(conf_mat, index = ['Negative (No Churn)', 'Positive (Churn)'], columns = ['Negative (No Churn)', 'Positive (Churn)'])\n",
                "    plt.figure(figsize=(5.5,4))\n",
                "    sns.heatmap(conf_mat_df, annot=True, fmt='g', cmap='Blues')\n",
                "    plt.title('Matriz de confusión')\n",
                "    plt.ylabel('True')\n",
                "    plt.xlabel('Predicted')\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_metrics(y_test, y_pred):\n",
                "    # accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
                "\n",
                "    print('Accuracy: %.3f' % accuracy_score(y_test, y_pred))\n",
                "\n",
                "    # recall = tp / (tp + fn)\n",
                "\n",
                "    print('Recall: %.3f' % recall_score(y_test, y_pred))\n",
                "\n",
                "    # precision = tp / (tp + fp)\n",
                "\n",
                "    print('Precision: %.3f' % precision_score(y_test, y_pred))\n",
                "\n",
                "    # specificity = tn / (tn + fp)\n",
                "\n",
                "    print('Specificity: %.3f' % (tn / (tn + fp)))\n",
                "\n",
                "    # f1 = 2 * (precision * recall) / (precision + recall)\n",
                "\n",
                "    print('F1 score: %.3f' % f1_score(y_test, y_pred))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_roc_curve(y_test, y_pred_proba):\n",
                "    \n",
                "    fpr_log,tpr_log,thr_log = roc_curve(y_test, y_pred_proba[:,1])\n",
                "    plt.plot([0, 1], [0, 1], 'k--')\n",
                "    plt.plot(fpr_log, tpr_log, label='GNB')\n",
                "    plt.xlabel('False Positive Rate')\n",
                "    plt.ylabel('True Positive Rate')\n",
                "    plt.title('GNB ROC Curve')\n",
                "    plt.show()\n",
                "\n",
                "    # AUC - Area Under the Curve\n",
                "\n",
                "    auc = roc_auc_score(y_test, y_pred_proba[:,1])\n",
                "    print('AUC: %.2f' % auc)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def compare_thresholds(y_test, y_pred_proba):\n",
                "    thresholds = np.arange(0, 1, 0.01)\n",
                "    accuracy = []\n",
                "    recall = []\n",
                "    precision = []\n",
                "    specificity = []\n",
                "    f1 = []\n",
                "    for i in thresholds:\n",
                "        y_pred = binarize(y_pred_proba, threshold=i)[:,1]\n",
                "        accuracy.append(accuracy_score(y_test, y_pred))\n",
                "        recall.append(recall_score(y_test, y_pred))\n",
                "        precision.append(precision_score(y_test, y_pred))\n",
                "        specificity.append(tn / (tn + fp))\n",
                "        f1.append(f1_score(y_test, y_pred))\n",
                "    plt.plot(thresholds, accuracy, label='accuracy')\n",
                "    plt.plot(thresholds, recall, label='recall')\n",
                "    plt.plot(thresholds, precision, label='precision')\n",
                "    plt.plot(thresholds, specificity, label='specificity')\n",
                "    plt.plot(thresholds, f1, label='f1')\n",
                "    plt.legend()\n",
                "    plt.xlabel('threshold')\n",
                "    plt.ylabel('score')\n",
                "    plt.show()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Naive Bayes"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Modelo"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "gnb = GaussianNB()\n",
                "\n",
                "gnb.fit(X_train, y_train)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "y_pred = gnb.predict(X_test)\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Métricas"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "create_confusion_matrix(y_test, y_pred)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "create_metrics(y_test, y_pred)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "y_pred_proba = gnb.predict_proba(X_test)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "create_roc_curve(y_test, y_pred_proba)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "compare_thresholds(y_test, y_pred_proba)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "El hecho que el mejor threshold sea 1 indica que el modelo no es capaz de predecir correctamente los casos de churn ya que la mejor opción es predecir que todos los clientes se quedan que es la hipótesis nula."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## KNN"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Modelo"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Métricas"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Regresión logística"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Modelo"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Métricas"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusiones"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "dh",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.4"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "de0c11672bdc465268fe040a07375f6ad60f942d46756d33f7fe9e449a78b4ed"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
