{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Trabajo práctico 1 : Analisis exploratorio del dataset Properatti\n",
                "\n",
                "Grupo #11: Camila Coltriani, Irania Fuentes, Johnatan Fischelson, Luis Dartayet, Ornela Cevolli  "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Introducción: \n",
                "El dataset Properatti está construido con los datos de venta de propiedades en diferentes provincias de Argentina; incluye ubicacion política y georeferenciada, así como los precios, superficie, cantidad de habitaciones y pisos, expensas y, otras informaciones. En este dataset cada fila es una propiedad en venta."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Identificar el problema ¿o cambiar por objetivos?"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "El objetivo de este trabajo es realizar una limpieza del dataset properatti con la finalidad de obtener un dataset final con datos confiables que pueda ser utilizado en la generación de un modelo estadistico posterior.\n",
                "Con base en esto se plantean los siguientes objetivos especificos:\n",
                " - Adquirir los datos: leer y conocer su estructura para determinar las herramientas apropiadas para su manipulación.\n",
                "\n",
                " - Parsear los datos: realizar el analisis exploratorio de los datos que permita verificar la existencia o no de relaciones entre variables, valores duplicados, valores faltantes, valores atípicos o valores erroneos que para validar o aumentar la confiabilidad de los datos.\n",
                "\n",
                " - Minar los datos: aplicar las herramientas de python para corregir datos erroneos o duplicados, completar/eliminar valores nulos.\n",
                " \n",
                " - Refinar los datos: eliminar variables redundantes o repetidas, crear nuevas variables y dar un formato limpio al dataset original."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Adquirir y visualizar el dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#librerías utilizadas para la adquisición de los datos\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "#import statsmodels.api as sm\n",
                "import seaborn as sns\n",
                "import geopandas as gpd\n",
                "import shapely.wkt"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "TODO: otros recursos utilizados\n",
                "- archivo de id_geonames: ar_copy.csv\n",
                "- archivo de barrios Argentina: barrios.csv "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Leemos y cargamos el dataset properatti.csv en una variable \n",
                "data = pd.read_csv(\"./properatti.csv\", index_col=0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualización de la forma y atributos del dataset \n",
                "print(data.shape)\n",
                "print(\"El dataset está compuesto por:\", data.shape[0], \"filas y\",data.shape[1],\"columnas.\")\n",
                "data.sample(5) #"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Descripción de las columnas del dataset:\n",
                "\n",
                "Los atributos o columas que incluye son:\n",
                "\n",
                "● unmaded: 0: indice de filas\n",
                "\n",
                "● property_type: tipo de inmueble en venta (casa, departamento, ph...)\n",
                "\n",
                "● operation: tipo de operacion inmobiliaria para las propiedades \n",
                "\n",
                "● place_name: ubicacion del inmueble por ciudad/Partido o barrios\n",
                "\n",
                "● place_with_parent_names: ubicacion agrupada del inmueble (Pais|Provincia|Partido o barrio)\n",
                "\n",
                "● country_name: nombre del país donde ocurre la operacion inmobiliaría\n",
                "\n",
                "● state_name: ubicacion del inmueble por provincia\n",
                "\n",
                "● geonames_id: número de identificación en la base de datos GeoNames asociado a la ubicacion por coordenadas\n",
                "\n",
                "● lat-lon: ubicacion de latitud y longitud concatenada\n",
                "\n",
                "● lat  ●lon: ubicacion de latitud y longitud en columnas separadas\n",
                "\n",
                "● price: precio del inmueble\n",
                "\n",
                "● currency: divisa en la que está expresado el precio del inmueble\n",
                "\n",
                "● price_aprox_local_currency: Precio aproximado en la moneda local del país de publicación\n",
                "\n",
                "● surface_total_in_m2: superficie total m² del inmueble\n",
                "\n",
                "● surface_covered_in_m2: Superficie cubierta en m²\n",
                "\n",
                "● price_usd_per_m2: Precio en dolares por metro cuadrado (USD/m²: precio dólares / superficie)\n",
                "\n",
                "● price_per_m2: Precio del metro cuadrado del inmueble\n",
                "\n",
                "● floor: N° de piso (cuando corresponde)\n",
                "\n",
                "● room: cantidad de habitaciones\n",
                "\n",
                "● expenses: expensas (cuando corresponde)\n",
                "\n",
                "● properati_url\t: URL de la inmobiliaría Properati en la Web\n",
                "\n",
                "● description: descripción del inmueble en la publicación Web\n",
                "\n",
                "● title: título del inmueble en la publicación\n",
                "\n",
                "● image_thumbnail: URL de un thumbnail de la primer foto en la Web"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Parsear los datos"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Analisis exploratorio general del dataset de Properatti"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Identificamos el tipo de dato de cada columna\n",
                "data.dtypes\n",
                "# El tipo de datos para variables cuantitativas discreta como floor y rooms deberia ser int, \n",
                "# posiblemente tengamos que realizar el cambio en su manipulación."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Realizamos una descripcion estadística de todas las columnas que resume la tendencia central, la dispersión y\n",
                "# la forma de la distribución de un conjunto de datos\n",
                "data.describe(include=\"all\")\n",
                "\n",
                "# Algunas interpretaciones/inferencias:\n",
                "# operation y country_name tiene 1 solo dato:  Sell y Argentina, como ya sabiamos, el dataset son datos de venta en Argentina\n",
                "# Existen cuatro tipos de propiedades en venta, la más frecuente es apartamento\n",
                "# Placename tiene como dato más frecuente la ciudad de Cordoba y state_name tiene a Capital Federal\n",
                "# lat-long hay datos repetidos o son los mismos edificios representados en un area determinada\n",
                "# Existen valores maximos muy alejados del resto de datos en las columnas de superfice, floor y rooms, posibles outliers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Identificamos los valores unicos x columna\n",
                "for columnas in data.columns:\n",
                "    print(\"\")\n",
                "    print(f'Nombre:{columnas}')\n",
                "    print(data[columnas].value_counts())\n",
                "\n",
                "#de esta funcion sumamos información general sobre el data set:\n",
                "#  identificamos los tipos de inmueble en venta: apartamentos y casas concentran la mayoria de datos\n",
                "#  las divisas más utilizadas son el peso argentina y dolares, hay datos que podemos tomar como no representativos:\n",
                "#  el PEN: peso peruano y UYU: peso uruguayo ya que no pasan de dos registros en el dataset. \n",
                "# para floor y rooms hay que tratar los valores outliers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Identificamos los registros nan por columna\n",
                "\n",
                "print(data.isna().sum())\n",
                "#price, currency, price_aprox, price_usd tienen la misma cantidad de nulos 20410\n",
                "#hay que averiguar si price_per_m2 es la relacion de price y surface_total, así podriamos completar nulos en price_per_m2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Vemos la relacion de registros nan con respecto al total de registros\n",
                "data.isna().sum()/data.shape[0] *100\n",
                "\n",
                "#podriamos completar place_name por el %bajo de nan\n",
                "#el mayor % de nan se encuentra en floor, rooms y expensas"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Análisis de datos faltantes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#creamos un nuevo dataframe con la suma de todos los registros nan por columna y el % que representan en forma decreciente\n",
                "missing_data = data.isna().sum(axis=0)\n",
                "missing_data_df = pd.DataFrame(missing_data, columns=['total_nan'])\n",
                "missing_data_df['perc_%'] = (missing_data_df / data.shape[0]).round(2)*100\n",
                "missing_data_df.sort_values(ascending=False, by='total_nan')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Dispersión de datos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_dispersion = data.apply(lambda x: x.unique().size)\n",
                "data_dispersion_df = pd.DataFrame(data_dispersion, columns=['count'])\n",
                "data_dispersion_df[\"perc\"] = (data_dispersion / data.shape[0]).round(2)*100\n",
                "data_dispersion_df.sort_values(ascending=True, by='count')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for col in data.columns:\n",
                "    if(data[col].nunique() < 100):\n",
                "        print(col)\n",
                "        print(data[col].unique())\n",
                "        print()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Analisis de correlacion entre columnas"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Identificamos si existe una correlacion entre variables\n",
                "corr = data.set_index('place_name').corr()\n",
                "sm.graphics.plot_corr(corr, xnames=list(corr.columns))\n",
                "plt.show()\n",
                "\n",
                "#Hay una alta correlacion entre price y price_per_m2, price_aprox_local_currency, price_aprox_usd: price está en dolares/pesos argentinos y local currency \n",
                "# en pesos, podría deberse al tipo de cambio utilizado."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Exploración del dataset dividido en grupos de Properatti "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Para los siguientes pasos trabajaremos con el dataset dividido en tres grandes grupos:\n",
                "-  Localización: que contiene las columnas relacionadas con la ubicación del inmueble y a su vez este dividido en dos subgrupos:\n",
                "  - Ubicación: que contiene las columnas place_name, state_name, country_name y place_with_parent_names, es decir columnas con la localización política del inmueble.\n",
                "  - Georeferenciada: que contiene las columnas geonames_id, lat y lon, es decir columnas con la localización geográfica del inmueble.\n",
                "- Precio: que contiene las columnas relacionadas a los precios en distintas variantes. \n",
                "- Superficie: que contiene las columnas relacionadas con la superficie del inmueble"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Definimos 4 grupos de columas para poder trabajar con ellas de forma mas sencilla\n",
                "places = ['place_name','place_with_parent_names', 'country_name','state_name']\n",
                "geolocation = ['geonames_id', 'lat-lon','lat','lon']\n",
                "price = ['price','currency','price_aprox_local_currency','price_aprox_usd','price_usd_per_m2','price_per_m2']\n",
                "surface = ['surface_total_in_m2','surface_covered_in_m2']"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Localización por ubicación política"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Exploración de las columnas relacionadas con la ubicación: Por Provincia, Ciudad/Barrio, el conjunto de ubicación \n",
                "- country_name\n",
                "- state_name \n",
                "- place_name                        \n",
                "- place_with_parent_names              \n",
                "\n",
                "vamos a:\n",
                "\n",
                "- Explorar las columnas \n",
                "- Visualizar los nan de estas columnas\n",
                "- Relacionar las columnas country_name, state_name, place_name con la concatenación de ubicación en place_with_parent_names para ver si efectivamente corresponden o hay datos mal cargados"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Creamos un nuevo dataframe con las columnas que nos interesan\n",
                "location_data = data[places].copy()\n",
                "location_data.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "places_data = data[places].copy()\n",
                "places_data.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "places_data.sample(10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#count: cuenta el numero de registros (no incluye null)\n",
                "#unique:  número de objetos distintos en la columna,\n",
                "#top: es el dato más frecuente que se produce,\n",
                "#freq: es la cantidad de veces que aparece el objeto “top” en la columna\n",
                "\n",
                "places_data[places].describe()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#ubicacion por provincia \"State_name\"\n",
                "#notamos que los datos estan concentrados en Buenos Aires (Cap fed, zona norte, zona sur, oeste, atlantica, interior),\n",
                "#  Cordoba, Santa fe \n",
                "\n",
                "places_data[\"state_name\"].value_counts() #Excludes NA values by default."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#ubicacion por ciudad-partido o barrio\n",
                " \n",
                "places_data[\"place_name\"].value_counts().head(20)\n",
                "\n",
                "#Tigre es una ciudad al norte de la ciudad de Buenos Aires.\n",
                "# Nordelta es una localidad urbana en el Partido de Tigre, Provincia de Buenos Aires \n",
                "\n",
                "##esta columna mezcla ciudades y barrios\n",
                "\n",
                "#Capital Federal está como place_name, "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Vemos algunos registros de place_with_parent_names\n",
                "places_data[\"place_with_parent_names\"].value_counts().head(10) \n",
                "\n",
                "#el atributo representa el país/ \"country_name\", la provincia/ \"state_name\" (o division de la provincia), la ciudad principal/partido-municipio o barrio en el caso de capital federal\"place_name\"\n",
                "#y un adicional que puede ser una localidad del partido (ejem: |Argentina|Bs.As. G.B.A. Zona Norte|Tigre|*Nordelta*|)\n",
                "#el registro tiene entre 2  y 4 concatenaciones: 2 concatenaciones solo muestra hasta la ubicación por provincia, no brinda información relevante\n",
                "\n",
                "\n",
                "###|Argentina|Capital Federal|  1297 no tiene nombre de barrio, desestimar o completar? \n",
                "#|Argentina|Córdoba|    2648\n",
                "\n",
                "#esta columna puede usarse para completar los datos faltantes de place_name \n",
                "#podemos chequear si el atributo \"place_name\" coincide con los datos aquí plasmados"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Para state_name vemos: cuales son los datos de place_name más frecuente, su frecuencia y cuantos registros diferentes existen \n",
                "\n",
                "places_data.groupby([\"state_name\"])[\"place_name\"].describe()\n",
                "\n",
                "#el atributo de place_name está representado principalmente por una ciudad-partido de la provincia\n",
                "\n",
                "#count: cuenta el numero de registros no incluye null\n",
                "#unique:  número de objetos distintos en la columna,\n",
                "#top: es el dato más frecuente que se produce,\n",
                "#freq: es la cantidad de veces que aparece el objeto “top” en la columna"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Verificar la calidad de los datos:\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Ubicación"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Para verificar la calidad de los datos principalmente vamos a comparar las columnas que deberían tener la misma información y ver si coinciden o no. Por ejemplo, la columna \"place_with_parent_names\" debería contener dentro de su array la misma información que \"place_name\". Vamos a verificar si esto es cierto o no."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Corroborar si place_with_parent_names coincide con country_name, state_name, place_name "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Convertimos la columna place_with_parent_names en una lista usando el separador \"|\"\n",
                "# Eliminamos el separador inicial y final de la lista\n",
                "places_data['place_with_parent_names'] = places_data['place_with_parent_names'].apply(lambda x: x.lstrip(\"|\").rstrip(\"|\").split(\"|\"))\n",
                "places_data['place_with_parent_names'].head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Función para chequear si los valores de la columna place_with_parent_names coinciden exactamente con \n",
                "# los valores de las columnas country_name, state_name, place_name\n",
                "# Coincidir exactamente significa que la columna place_with_parent_names sólo tiene 3 elementos \n",
                "# y que los valores de los elementos coinciden en orden con los valores de las columnas country_name, state_name, place_name\n",
                "\n",
                "def is_location_different(row):\n",
                "    # la lista debería tener 3 elementos\n",
                "    if len(row['place_with_parent_names']) != 3:\n",
                "        return True\n",
                "    if row['country_name'] == row['place_with_parent_names'][0] \\\n",
                "    and row['state_name'] == row['place_with_parent_names'][1] \\\n",
                "    and row['place_name'] == row['place_with_parent_names'][2]:\n",
                "        return False\n",
                "    else:\n",
                "        return True"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Creamos la mascara utilizando la función is_location_different\n",
                "mask = places_data.apply(lambda x: is_location_different(x), axis=1)\n",
                "print(\"place_with_parent_names difference with country_name, state_name and place_name:\", places_data[mask].shape[0])\n",
                "places_data[mask][places].sample(10)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "*Conclusión: Existen 45220 registros que no coinciden exactamente.* "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Análisis de los registros que no coinciden exactamente en las columnas places\n",
                "___"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Veamos cuáles son los registros que no coinciden exactamente en las columnas places"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Contamos la cantidad de valores de cada fila de la lista place_with_parent_names\n",
                "places_data['place_with_parent_names'].apply(lambda x: len(x)).value_counts()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Los que no coinciden exactamente son aquellas listas que no tienen 3 valores. Revisamos que los valores que están en cada lista tengan su contraparte en las otras columnas aunque figuren en otro orden del array. Por ejemplo, si en place_with_parent_names figura \"Argentina|Capital Federal|Palermo\" y en place_name figura \"Capital Federal\", entonces el registro para este momento del análisis se considera válido."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# country_name\n",
                "print(\"null values:\", places_data['country_name'].isna().sum())\n",
                "mask = ~places_data.apply(lambda x: x['country_name'] in x['place_with_parent_names'], axis=1)\n",
                "print(\"place_with_parent_names difference with country_name:\", places_data[mask].shape[0])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# state_name\n",
                "print(\"null values:\", places_data['state_name'].isna().sum())\n",
                "mask = ~places_data.apply(lambda x: x['state_name'] in x['place_with_parent_names'], axis=1)\n",
                "print(\"place_with_parent_names difference with state_name:\", places_data[mask].shape[0])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# place_name\n",
                "print(\"null values:\", places_data['place_name'].isna().sum())\n",
                "mask = ~places_data.apply(lambda x: x['place_name'] in x['place_with_parent_names'], axis=1)\n",
                "print(\"place_with_parent_names difference with place_name:\", places_data[mask].shape[0])\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "*Conclusión: La información que figura en las columnas place_name, country_name y state_name se encuentra en la columna place_with_parent_names aunque no exactamente igual (parece existir información extra) excepto en la columna 'place_name' con sus 23 NaNs que ya hemos identificado previamente.*"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "A continuación analizaremos esas columnas dividiendo el trabajo en partes dependiendo de la cantidad de elementos que contenga el array de la columna \"place_with_parent_names\"."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Análisis de registros de place_with_parent_names con 3 valores\n",
                "___"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Revisamos los place_with_parent_names con tres elementos\n",
                "mask = places_data['place_with_parent_names'].apply(lambda x: len(x) == 3)\n",
                "places_data_3_elements = places_data[mask].copy()\n",
                "places_data_3_elements.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Corroboramos que los valores de country_name, state_name y place_name coinciden con los valores de place_with_parent_names\n",
                "print(\"country_name difference with place_with_parent_names[0]:\", places_data_3_elements[places_data_3_elements['country_name'] != places_data_3_elements['place_with_parent_names'].apply(lambda x: x[0])].shape[0])\n",
                "print(\"state_name difference with place_with_parent_names[1]:\", places_data_3_elements[places_data_3_elements['state_name'] != places_data_3_elements['place_with_parent_names'].apply(lambda x: x[1])].shape[0])\n",
                "print(\"place_name difference with place_with_parent_names[2]:\", places_data_3_elements[places_data_3_elements['place_name'] != places_data_3_elements['place_with_parent_names'].apply(lambda x: x[2])].shape[0])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Vemos los datos correspondientes a los valores nulos de la columna place_name\n",
                "mask = ~places_data.apply(lambda x: x['place_name'] in x['place_with_parent_names'], axis=1)\n",
                "places_data_place_name_nan = places_data[mask].copy()\n",
                "places_data_place_name_nan.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "places_data_place_name_nan['place_with_parent_names'].apply(lambda x: x[2]).value_counts()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "*Conclusión: Los registros que no tienen valor en place_name son los que no coinciden, todos del municipio de Tigre. El resto de los valores son exactamente iguales*  \n",
                "\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Análisis de registros de place_with_parent_names con 4 valores\n",
                "___"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Revisamos los place_with_parent_names con cuatro elementos\n",
                "mask = places_data['place_with_parent_names'].apply(lambda x: len(x) == 4)\n",
                "places_data_4_elements = places_data[mask].copy()\n",
                "places_data_4_elements['place_with_parent_names'].shape\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Contamos los valores de la columna place_with_parent_names por el segundo elemento (descartamos el primero porque sabemos que siempre es Argentina)\n",
                "places_data_4_elements['place_with_parent_names'].apply(lambda x: x[1]).value_counts()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Confirmamos que los valores de la columna place_with_parent_names[1] coinciden con los valores de la columna state_name\n",
                "mask = (places_data_4_elements['place_with_parent_names'].apply(lambda x: x[1]) != places_data_4_elements['state_name'])\n",
                "print(\"place_with_parent_names[1] difference with state_name:\", places_data_4_elements[mask].shape[0])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Confirmamos que los valores de la columna place_with_parent_names[2] coinciden con los valores de la columna place_name\n",
                "mask = places_data_4_elements['place_with_parent_names'].apply(lambda x: x[2]) != places_data_4_elements['place_name']\n",
                "print(\"place_with_parent_names[2] difference with place_name:\", places_data_4_elements[mask].shape[0])\n",
                "print(\"place_with_parent_names[2] proportional difference with place_name:\", places_data_4_elements[mask].shape[0] / places_data_4_elements.shape[0])\n",
                "places_data_4_elements_non_matching = places_data_4_elements[mask].copy()\n",
                "places_data_4_elements_non_matching[places].sample(10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# No coinciden en 29842 registros pero coinciden en el resto. \n",
                "# Confirmamos que los que coinciden son iguales al valor[3]\n",
                "mask = places_data_4_elements_non_matching['place_with_parent_names'].apply(lambda x: x[2]) == places_data_4_elements_non_matching['place_with_parent_names'].apply(lambda x: x[3])\n",
                "places_data_4_elements_non_matching[mask].shape[0]/ places_data_4_elements_non_matching.shape[0]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Confirmamos que los valores de la columna place_with_parent_names[3] coinciden con los valores de la columna place_name\n",
                "mask = (places_data_4_elements['place_with_parent_names'].apply(lambda x: x[3]) != places_data_4_elements['place_name'])\n",
                "print(\"place_with_parent_names[3] difference with place_name:\", places_data_4_elements[mask].shape[0])\n",
                "anti_mask = ~mask # Los que coinciden\n",
                "places_data_4_elements[anti_mask][places].sample(10)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "*Conclusión: De los 39869 registros con 4 valores, 29842 toman el valor de place_name del 4to valor de la lista. Los 10027 restantes toman el 3er valor.*\n",
                "\n",
                "- place_name asignado a 3er valor de \"place_with_parent_names\": 10027\n",
                "- place_name asignado a 4to valor de \"place_with_parent_names\": 29842"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Análisis de registros de place_with_parent_names con 2 valores\n",
                "___"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Reviso los place_with_parent_names con dos elementos\n",
                "mask = places_data['place_with_parent_names'].apply(lambda x: len(x) == 2)\n",
                "places_data_2_elements = places_data[mask].copy()\n",
                "places_data_2_elements['place_with_parent_names'].value_counts()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Reviso los place_with_parent_names de Córdoba y Capital Federal\n",
                "mask = places_data_2_elements['place_with_parent_names'].apply(lambda x: x[1] == 'Córdoba' or x[1] == 'Capital Federal')\n",
                "places_data_2_elements[mask].sample(10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Pareciera ser que todos los lugares que tienen dos elementos en place_with_parent_names repiten el nombre del estado en place_name\n",
                "# Corroboramos esto\n",
                "mask = places_data_2_elements['place_name'] != places_data_2_elements['state_name']\n",
                "places_data_2_elements[mask].shape\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "*Conclusión: En los 4780 registros de place_with_parent_names que tienen 2 valores se utilizó state_name como place_name.*\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Análisis de registros de place_with_parent_names con 5 valores\n",
                "___"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Reviso los place_with_parent_names con 5 elementos\n",
                "mask = places_data['place_with_parent_names'].apply(lambda x: len(x) == 5)\n",
                "places_data_5_elements = places_data[mask].copy()\n",
                "places_data_5_elements['place_with_parent_names'].shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Reviso si alguno de los valores no corresponde a Nordelta\n",
                "places_data_5_elements['place_with_parent_names'].apply(lambda x: x[3] != 'Nordelta').sum()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Corroboramos que los valores de la columna place_with_parent_names[2] coinciden con los valores de la columna place_name\n",
                "mask = (places_data_5_elements['place_with_parent_names'].apply(lambda x: x[2]) != places_data_5_elements['place_name'])\n",
                "print(\"place_with_parent_names[2] difference with place_name:\", places_data_5_elements[mask].shape[0])\n",
                "print(\"place_with_parent_names[2] proportional difference with place_name:\", places_data_5_elements[mask].shape[0] / places_data_5_elements.shape[0])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Corroboramos que los valores de la columna place_with_parent_names[3] coinciden con los valores de la columna place_name\n",
                "mask = (places_data_5_elements['place_with_parent_names'].apply(lambda x: x[3]) != places_data_5_elements['place_name'])\n",
                "print(\"place_with_parent_names[3] difference with place_name:\", places_data_5_elements[mask].shape[0])\n",
                "print(\"place_with_parent_names[3] proportional difference with place_name:\", places_data_5_elements[mask].shape[0] / places_data_5_elements.shape[0])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Corroboramos que los valores de la columna place_with_parent_names[4] coinciden con los valores de la columna place_name\n",
                "mask = (places_data_5_elements['place_with_parent_names'].apply(lambda x: x[4]) != places_data_5_elements['place_name'])\n",
                "print(\"place_with_parent_names[4] difference with place_name:\", places_data_5_elements[mask].shape[0])\n",
                "print(\"place_with_parent_names[4] proportional difference with place_name:\", places_data_5_elements[mask].shape[0] / places_data_5_elements.shape[0])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "*Conclusión: Los 548 registros de place_with_parent_names que tienen 5 valores son de Nordelta y el último valor se refiere al Barrio. place_name toma los valores del barrio*"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "> ##### Conclusiones finales: \n",
                "> - Existen como máximo 5 tipos de registros en place_with_parent_names: Country, State, Municipio, Ciudad, Barrio\n",
                "> - Country y State son iguales a country_name y state_name\n",
                "> - Place_name se le asigna el valor de municipio: 76000 + 10027 = 86027\n",
                "> - Place_name se le asigna el valor de ciudad: 29842 (en  estos casos existe el valor municipio también)\n",
                "> - Place_name se le asigna el valor de barrio: 548 (en estos casos existe el valor municipio y ciudad también)\n",
                "> - Place_name se le asigna el valor de state_name: 4780 (en estos casos no existe el valor municipio y ciudad)\n",
                "> - Place_name se le asigna el valor de NaN: 23 (en estos casos existe el valor municipio y ciudad)\n",
                "> ___\n",
                "> Por lo tanto se puede concluir que para dar mayor consistencia es posible imputar place_name con el valor del municipio en las mayoría de los casos. Confrontar con geoNamesId.\n",
                "> ___\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Geolocalización"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Creamos un nuevo dataframe con las columnas que me interesan\n",
                "geo_location_data = data[ geolocation].copy()\n",
                "geo_location_data.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Analizamos por lat-lon para si había duplicados considerando que las mismas coordenadas son las misma propiedad.\n",
                "\n",
                "No es posible determinar si es la misma propiedad porque lat-lon se refiere muchas veces a la ubicación aproximada. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## ver datos duplicados\n",
                "data_copy = data.copy()\n",
                "data_copy.dropna(subset=['lat-lon'], inplace=True)\n",
                "data_copy_group = data_copy.groupby('lat-lon').count()\n",
                "data_copy_group[data_copy_group['operation'] > 1].sort_values(by='operation', ascending=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## ver si existe algun dato duplicado\n",
                "data.duplicated().any()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data['lat-lon'].duplicated().any()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_copy.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_copy[data_copy['lat-lon'] == '-34.4026444,-58.6684776']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "geo_location_data.sample(10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Vemos porcentaje de valores nulos por columna\n",
                "geo_location_data.isnull().sum()/geo_location_data.shape[0] * 100\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# convertimos el dataframe a geodataframe\n",
                "geo_location_data_gdf = gpd.GeoDataFrame(geo_location_data, geometry=gpd.points_from_xy(geo_location_data.lon, geo_location_data.lat))\n",
                "\n",
                "# Ubicamos los puntos en el mapa\n",
                "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
                "latin_america = world[world['continent'] == 'South America']\n",
                "fig, ax = plt.subplots(figsize=(5,10))\n",
                "latin_america.plot(ax=ax, alpha=0.4, color='grey', edgecolor='black')\n",
                "geo_location_data_gdf.plot(ax=ax, markersize=0.5, color='red')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Existe una propiedad que se encuentra fuera de la Argentina (en Colombia). \n",
                "# La buscamos en el dataframe original\n",
                "# buscamos el polígono de Colombia\n",
                "geo_colombia = world[world['name'] == 'Colombia']\n",
                "\n",
                "# Buscamos la propiedad que se encuentra en Colombia\n",
                "geo_outlier_index = geo_location_data_gdf[geo_location_data_gdf.within(geo_colombia['geometry'].iloc[0])].index\n",
                "\n",
                "# La buscamos en el dataframe original\n",
                "data.iloc[geo_outlier_index]\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Es una propiedad súper interesante, por latitud y longitud está en Colombia, pero por el nombre de la provincia está en Argentina, la descripción habla de Armenia y el título del el Barrio el Limonar.\n",
                "\n",
                "En una rápida búsqueda por internet encontramos que la propiedad se encuentra en el barrio El Limonar de Armenia, Colombia.\n",
                "\n",
                "La descartaremos sin dudas.\n",
                "\n",
                "______"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Corroborar si lat-lon coincide con las columnas lat y lon"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Corroboremos que los valores nulos en lat-lon son los mismos que en lat y lon\n",
                "geo_location_data[geo_location_data['lat-lon'].isnull()]['lat'].isnull().sum() == geo_location_data[geo_location_data['lat-lon'].isnull()]['lon'].isnull().sum()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Dropeamos los valores nulos de lat-lon\n",
                "geo_location_data.dropna(subset=['lat-lon'], inplace=True)\n",
                "geo_location_data.isnull().sum()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Convertimos la columna lat-lon en dos columnas nuevas\n",
                "geo_location_data['lat_alt'] = geo_location_data['lat-lon'].apply(lambda x: x.split(',')[0])\n",
                "geo_location_data['lon_alt'] = geo_location_data['lat-lon'].apply(lambda x: x.split(',')[1])\n",
                "geo_location_data.head()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Vemos los tipos de datos\n",
                "geo_location_data.dtypes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# convertimos las nuevas columnas a float\n",
                "geo_location_data['lat_alt'] = geo_location_data['lat_alt'].astype(float)\n",
                "geo_location_data['lon_alt'] = geo_location_data['lon_alt'].astype(float)\n",
                "geo_location_data.dtypes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Comprobamos que los valores de las nuevas columnas son iguales a los de las columnas originales\n",
                "print(\"Diferencia entre lat:\",(geo_location_data['lat_alt'] != geo_location_data['lat']).sum())\n",
                "print(\"Diferencia entre lon:\",(geo_location_data['lon_alt'] != geo_location_data['lon']).sum())\n",
                "# En proporción\n",
                "print(\"Diferencia en proporción de lat\",(geo_location_data['lat_alt'] != geo_location_data['lat']).sum()/ geo_location_data.shape[0])\n",
                "print(\"Diferencia en proporción de lon\",(geo_location_data['lon_alt'] != geo_location_data['lon']).sum()/ geo_location_data.shape[0])\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Hay diferencias en 21% los casos. Veamos si es una diferencia significativa\n",
                "\n",
                "Revisamos el margen de diferencia redondeando progresivamente."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "Decimal(geo_location_data['lon'][0]).as_tuple().exponent"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Reviso la cantidad de decimales que tienen los valores de lat y lon\n",
                "geo_location_data['lat'].apply(lambda x: Decimal(x).as_tuple().exponent).value_counts()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "geo_location_data['lon'].apply(lambda x: Decimal(x).as_tuple().exponent).value_counts()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Vamos redondeando progresivamente los valores de lat y lon\n",
                "lat_decimal_diff = []\n",
                "for i in range(47,0,-1):\n",
                "    margin = (geo_location_data['lat_alt'].round(i) != geo_location_data['lat'].round(i)).sum()/ geo_location_data.shape[0]\n",
                "    lat_decimal_diff.insert(0,margin)\n",
                "    # print('Margen de diferencia de',i,'decimales en latitud:', margin)\n",
                "# Buscamos dónde el margen de diferencia es menor al 1%\n",
                "    if margin <= 0.01:\n",
                "        print('Margen de diferencia de',i,'decimales en latitud:', margin)\n",
                "   \n",
                "print(\"////////////////////////////////////\")   \n",
                "\n",
                "lon_decimal_diff = []\n",
                "for i in range(47,0,-1):\n",
                "    margin = (geo_location_data['lon_alt'].round(i) != geo_location_data['lon'].round(i)).sum()/ geo_location_data.shape[0]\n",
                "    lon_decimal_diff.insert(0,margin)\n",
                "    # print('Margen de diferencia de',i,'decimales en longitud:', margin)\n",
                "# Buscamos dónde el margen de diferencia es menor al 1%\n",
                "    if margin <= 0.01:\n",
                "        print('Margen de diferencia de',i,'decimales en latitud:', margin)\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Lo graficamos\n",
                "plt.figure(figsize=(10,5))\n",
                "plt.plot(lat_decimal_diff, label='latitud')\n",
                "plt.plot(lon_decimal_diff, label='longitud')\n",
                "plt.ylabel('Margen de diferencia')\n",
                "plt.xlabel('Cantidad de decimales')\n",
                "plt.legend()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "geo_location_data_gdf = gpd.GeoDataFrame(geo_location_data, geometry=gpd.points_from_xy(geo_location_data.lon, geo_location_data.lat))\n",
                "geo_location_data_gdf.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "> Como se puede ver, las diferencias entre lat-lon y lat y lon comienzan a partir de los 13 decimales por lo que podemos descartarla como una diferencia significativa.\n",
                "> \n",
                "> Por otro lado, también hemos comprobado que los valores de lat lon provienen de convertir la variable a geometry y obtener de ahí lat y lon\n",
                ">\n",
                "> Entonces podemos concluir que la variable lat-lon es redundante y podemos eliminarla.\n",
                "> ____ "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Análisis de propiedades con igual latitud y longitud con otras propiedades"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Vamos a buscar si hay muchos puntos iguales para refutar la hipótesis de que se utilizó la misma ubicación para varias propiedades"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Primero veamos una visualización de los datos de Capital Federal para ver si parece haber una gran concentración \n",
                "# de propiedades en algún lugar específico o están dispersas por toda la ciudad.\n",
                "geo_location_data_gdf_capital = geo_location_data_gdf[data['state_name']=='Capital Federal']\n",
                "geo_location_data_gdf_capital['geometry']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Ubicamos los puntos en el mapa\n",
                "df_barrios_capital = pd.read_csv('./data/barrios.csv', sep=',', encoding='latin-1')\n",
                "import shapely.wkt\n",
                "\n",
                "df_barrios_capital[\"WKT\"] = df_barrios_capital[\"WKT\"].apply(shapely.wkt.loads) \n",
                "df_barrios_capital = gpd.GeoDataFrame(df_barrios_capital, geometry='WKT')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "geo_location_data_gdf_capital['geometry']\n",
                "fig, ax = plt.subplots(figsize=(10,20))\n",
                "\n",
                "geo_location_data_gdf_capital.plot(ax=ax, markersize=0.5, color='red', alpha=0.1) \n",
                "df_barrios_capital.plot(ax=ax, alpha=0.4, color='grey', edgecolor='black')\n",
                "plt.xlim(-58.55,-58.350)\n",
                "plt.ylim(-34.705,-34.525) \n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Ahora veamos en todo el dataset cuántas propiedades comparten la misma ubicación.\n",
                "different_locations = geo_location_data_gdf['geometry'].value_counts()\n",
                "print('Cantidad de propiedades por punto:', different_locations) "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "prop_qty_per_point = []\n",
                "for i in range(1,different_locations[0]+1):\n",
                "    (different_locations == i).sum() / different_locations.shape[0] * 100\n",
                "    prop_qty_per_point.append((different_locations == i).sum() / different_locations.shape[0] * 100)\n",
                "prop_qty_per_point = pd.DataFrame(prop_qty_per_point, columns=['Porcentaje'], index=range(1,different_locations[0]+1))\n",
                "prop_qty_per_point.reset_index(inplace=True)\n",
                "prop_qty_per_point.rename(columns={'index':'Cantidad de propiedades por punto'}, inplace=True)\n",
                "prop_qty_per_point.head(10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Lo graficamos\n",
                "plt.figure(figsize=(10,5))\n",
                "plt.hist(different_locations, bins=different_locations[0]+1)\n",
                "plt.ylabel('Cantidad de puntos')\n",
                "plt.xlabel('Cantidad de propiedades por punto')\n",
                "plt.show()\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Veamos dónde se encuentran las propiedades que más tienen lat y lon iguales"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "most_shared_point_props = geo_location_data_gdf[geo_location_data_gdf['geometry'].isin(different_locations.index[0:11])]\n",
                " "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, ax = plt.subplots(figsize=(5,10))\n",
                "latin_america.plot(ax=ax, alpha=0.4, color='grey', edgecolor='black')\n",
                "most_shared_point_props.plot(ax=ax, markersize=0.5, color='red')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Parece que están todas en la Argentina\n",
                "# Descargamos un mapa de la Argentina por municipios para averiguar qué municipios son los que tienen más propiedades en el mismo punto.\n",
                "# https://www.ign.gob.ar/NuestrasActividades/InformacionGeoespacial/CapasSIG\n",
                "municipios_geo = gpd.read_file('./data/municipio/municipio.shp')\n",
                "municipios_geo.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, ax = plt.subplots(figsize=(5,10))\n",
                "municipios_geo.plot(ax=ax, alpha=0.4, color='grey', edgecolor='black')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Veamos en qué municipios están las propiedades que comparten el mismo punto.\n",
                "# convertimos a coordenadas geográficas para poder hacer el join con el geodataframe de las propiedades.\n",
                "most_shared_point_props.crs = \"EPSG:4326\"\n",
                "most_shared_point_props['geometry'] = most_shared_point_props['geometry'].to_crs(epsg=4326) "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Hacemos el join con el geodataframe de los municipios.\n",
                "most_shared_point_props_municipios = gpd.sjoin(most_shared_point_props, municipios_geo, how=\"inner\", op='intersects')\n",
                "most_shared_point_props_municipios.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "most_shared_point_props_municipios['fna'].value_counts()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "> Podemos concluir que la gran mayoría de los puntos de lat y lon son únicos, por lo que descartamos que sean aproximaciones.\n",
                ">  \n",
                "> Una excepción notable son Tigre y Capital Federal\n",
                "> \n",
                "> ____"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Corroborar si lat-lon coincide con geonames_id"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "geo_location_data = data[ geolocation].copy()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Corroboramos que todos los nulos de latitud y longitud también son nulos en la columna geonames_id.\n",
                "lat_nulls = geo_location_data[geo_location_data['lat'].isnull()]\n",
                "lon_nulls = geo_location_data[geo_location_data['lon'].isnull()]\n",
                "geonames_null = geo_location_data[geo_location_data['geonames_id'].isnull()]\n",
                "print('Es lat null = lon null?: ', lat_nulls.equals(lon_nulls))  \n",
                "print('Es lat null = geonames null?: ', lat_nulls.equals(geonames_null))  \n",
                "print('Es lon null = geonames null?: ', lon_nulls.equals(geonames_null))  \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Vemos cuantas columnas tienen nulos en lat (o lon, son iguales en cuanto a nulos) y no en geonames_id.\n",
                "lat_nulls = geo_location_data[geo_location_data['lat'].isnull()]\n",
                "lat_nulls_geonames_not_null = lat_nulls[lat_nulls['geonames_id'].notnull()]\n",
                "lat_nulls_geonames_not_null.shape[0] "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Vemos cuantas columnas tienen nulos en geonames_id y no en lat (o lon, son iguales en cuanto a nulos).\n",
                "geonames_null = geo_location_data[geo_location_data['geonames_id'].isnull()]\n",
                "geonames_null_lat_not_null = geonames_null[geonames_null['lat'].notnull()]\n",
                "geonames_null_lat_not_null.shape[0]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "> Conclusión: Podemos imputar lat y lon a partir de geonames_id en 43365 casos. \n",
                "> \n",
                "> Podríamos imputar 10532 casos en geonames pero con una sóla variable de geolocalización es suficiente y usaremos lat-lon para crear geometry.\n",
                ">  \n",
                "> ______"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##### Importar la información de geonames_id"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "geonames = pd.read_csv(\"ar_copy.csv\", sep='\\t', header=None)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#como no tengo nombres en la columnas para mejorar la extracción renombro las que me interesan\n",
                "geonames.rename({0: 'geoname_oficial', 4:\"lat_oficial\", 5:\"lon_oficial\"}, axis=1, inplace=True)\n",
                "geonames.head(4)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#ahora si vamos a buscar los datos de lat y lon desde el geoname_oficial del archivo geonames de internet\n",
                "#Creamos un diccionario vacío para ubicar la Latitud\n",
                "lat_dict = {}\n",
                "\n",
                "#Creamos una tupla con los pares de key y value: usando un iterador de tuplas zip donde el primer\n",
                "# elemento de cada iterador pasado se empareja con el primero del segundo y asi sucesivamente\n",
                "geoname_lat = zip(geonames['geoname_oficial'], geonames['lat_oficial'])\n",
                "\n",
                "#Rellenamos el diccionario\n",
                "for geoname, lat_oficial in geoname_lat:\n",
                "    lat_dict[geoname] = lat_oficial"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Creamos un diccionario para ubicar la Longitud\n",
                "lon_dict = {}\n",
                "\n",
                "#Creamos una tupla con los pares de key y value: usando un iterador de tuplas zip donde el primer\n",
                "# elemento de cada iterador pasado se empareja con el primero del segundo y asi sucesivamente\n",
                "geoname_lon = zip(geonames['geoname_oficial'], geonames['lon_oficial'])\n",
                "\n",
                "#Rellenamos el diccionario\n",
                "for geoname, lon_oficial in geoname_lon:\n",
                "    lon_dict[geoname] = lon_oficial"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "geo_location_data[\"lat_geoname\"] = geo_location_data['geonames_id'].map(lat_dict)\n",
                "geo_location_data[\"lon_geoname\"] = geo_location_data['geonames_id'].map(lon_dict)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "geo_location_data.isna().sum()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##### Comparar lat-lon con lat-lon extraído de geonames_id"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Esto no se puede hacer porque sólo se extrajeron los datos de geonames_id que no tenían lat-lon"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# comparo los datos completados con los datos originales para ver si hay diferencias\n",
                "# remuevo los nan de los datos originales (porque seguro va a haber diferencias en esos datos)\n",
                "geo_location_data.dropna(subset=['lat', 'lon','geonames_id', 'lat_geoname', \"lon_geoname\" ], inplace=True)\n",
                "geo_location_data.isna().sum()  "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "geo_location_data.shape "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# comparamos las filas en común que no tienen nulos\n",
                "geo_location_data['lat'] == geo_location_data['lat_geoname']\n",
                "geo_location_data[geo_location_data['lat'] != geo_location_data['lat_geoname']]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Ubicamos los puntos en el mapa\n",
                "geo_location_data_gdf = gpd.GeoDataFrame(geo_location_data, geometry=gpd.points_from_xy(geo_location_data.lon, geo_location_data.lat))\n",
                "geo_location_data_gdf_capital = geo_location_data_gdf[data['state_name']=='Capital Federal']\n",
                "geo_location_data_gdf_capital_geonames = gpd.GeoDataFrame(geo_location_data, geometry=gpd.points_from_xy(geo_location_data.lon_geoname, geo_location_data.lat_geoname))\n",
                "geo_location_data_gdf_capital['geometry']\n",
                "df_barrios_capital = pd.read_csv('./data/barrios.csv', sep=',', encoding='latin-1')\n",
                "\n",
                "\n",
                "df_barrios_capital[\"WKT\"] = df_barrios_capital[\"WKT\"].apply(shapely.wkt.loads) \n",
                "df_barrios_capital = gpd.GeoDataFrame(df_barrios_capital, geometry='WKT')\n",
                "\n",
                "geo_location_data_gdf_capital['geometry']\n",
                "fig, ax = plt.subplots(figsize=(10,20))\n",
                "\n",
                "geo_location_data_gdf_capital.plot(ax=ax, markersize=0.5, color='red', alpha=0.1) \n",
                "geo_location_data_gdf_capital_geonames.plot(ax=ax, markersize=0.5, color='blue', alpha=0.1)\n",
                "df_barrios_capital.plot(ax=ax, alpha=0.4, color='grey', edgecolor='black')\n",
                "plt.xlim(-58.55,-58.350)\n",
                "plt.ylim(-34.705,-34.525) \n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "*Conclusión: Geonames_id marca el centro de cada uno de los barrios y no la latitud y longitud exacta de la propiedad. Por lo que deberíamos imputar lat y lon a partir de geonames_id con mucho cuidado.*"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Precio"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Superficie"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Minar los datos"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Refinar los datos"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Exportar el nuevo dataset "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.10.4 ('DH_geopandas')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.4"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "ccc2d0a3504c81dc026caf32773f2f2f4469570f6fc589beb16b0e0e3d20cee5"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
