{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrantes:\n",
    "1. Camila Coltriani\n",
    "2. Luis Dartayet\n",
    "3. Irania Fuentes\n",
    "4. Jonathan Fichelson\n",
    "5. Ornella Cevoli\n",
    "# Trabajo práctico 2 : Modelo de regresión lineal del dataset Properatti\n",
    "## Objetivos\n",
    "El objetivo de este trabajo final es generar y comparar estadísticamente tres modelos de regresión lineal sobre el dataset limpio de Properatti construido en el TP_1; en este, fue planteado la hipótesis que el precio (variable objetivo) de las propiedades iba a estar influenciado principalmente por la superficie y la ubicación (variables predictoras). \n",
    "\n",
    "Con base a esto, se han planteado los siguientes objetivos específicos:\n",
    "- Explorar el dataset limpio con la finalidad de verificar si debe realizarse una ultima limpieza o pueden utilizase los datos directamente;\n",
    "- Realizar una visualización general de las distribuciones y relaciones del dataset con la finalidad de determinar la zona, tipo de inmueble y variables predictoras y objetivo para la realización de los modelos;\n",
    "- Construir modelos de regresión lineal simple y multiple e interpretar sus metricas con la finalidad de identificar el que mejor permita obtener una predicción confiable de la variable objetivo;\n",
    "- Implementar un modelo de regularización con la finalidad de compararlos y evaluar si existe o no problemas de sobreajuste;\n",
    "- Determinar el modelo que más se ajusta al comportamiento de los datos analizados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Las librerías utilizadas en este documento son:\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "from sklearn import metrics\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from matplotlib import gridspec\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de la forma y atributos del dataset\n",
    "data = pd.read_csv(\"./data/data_limpio_gdf.csv\")\n",
    "print(data.shape)\n",
    "print(\"El dataset está compuesto por:\", data.shape[0], \"filas y\",data.shape[1],\"columnas.\")\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descripción de las columnas del dataset limpio:\n",
    "\n",
    "Las columnas que incluye son:\n",
    "\n",
    "● municipio: ubicación del inmueble por su municipio/barrios\n",
    "\n",
    "● provincia: ubicación del inmueble por provincia\n",
    "\n",
    "● lat  ●lon: ubicación de latitud y longitud\n",
    "\n",
    "● superficie_m2_total: superficie total en m² del inmueble\n",
    "\n",
    "● price_usd: Precio en dólares del inmueble\n",
    "\n",
    "● tipo: tipo de inmueble en venta (casa, departamento, ph, tienda)\n",
    "\n",
    "● ambientes_cat: cantidad de ambientes del inmueble (0, 1, 2, 3 , 4 o más)\n",
    "\n",
    "● precio_usd_por_m2: Precio en dólares por metro cuadrado (USD/m²: precio dólares / superficie)\n",
    "\n",
    "● tipo_cat_code: categoría numérica de tipo de inmueble\n",
    "\n",
    "● municipio_cat_code: categoría numérica de municipios\n",
    "\n",
    "● provincia_cat_code: categoría numérica de provincia\n",
    "\n",
    "● tipo_cat_code: categoría numérica de ambientes_cat\n",
    "\n",
    "● geometry: figura geométrica de latitud y la longitud\n",
    "\n",
    "● country_name: nombre del país donde ocurre la operación inmobiliaria\n",
    "\n",
    "● **precio_usd_por_m2_cat: categoría numérica de precio_usd_por_m2**\n",
    "# Análisis exploratorio y visualización de correlaciones entre las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Revisamos la presencia de datos NaN\n",
    "data.isna().sum().sort_values()\n",
    "#La columna \"ambientes_cat\" quedó con 1248 registros nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_by_row=data.isna().sum().sort_values(ascending=False)[0:6]\n",
    "missing_by_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se realiza lo siguiente solo a fines de graficar \n",
    "missing_by_row=data.isna().sum().sort_values(ascending=False)[0:6]\n",
    "#se grafica cantidad de datos faltantes por fila del data set a fines practicos se visualizan solo las primeras 5 filas\n",
    "sns.barplot(x=missing_by_row.index, y=missing_by_row.astype(int)) \n",
    "plt.title(\"Cantidad de datos faltantes por filas\")\n",
    "plt.xlabel(\"Cantidad de datos faltantes\")\n",
    "plt.ylabel(\"Registros nulos\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviso donde están ubicados y a que propiedad pertenecen los registros nulos para saber si afectaran escoger un tipo de inmueble y su zona\n",
    "mascara_nulos = data[\"ambientes_cat\"].astype(str) == \"nan\" \n",
    "data_nulos = data[mascara_nulos]\n",
    "data_nulos.loc[:, [\"municipio\", 'tipo', 'ambientes_cat', \"precio_usd\"]].sample(7)\n",
    "#print(data[mascara_nulos].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se realiza lo siguiente solo a fines de graficar en presentacion.\n",
    "missing_by_row_2= data_nulos.groupby('municipio')['tipo'].count().sort_values(ascending=False).head(25)\n",
    "missing_by_row_2_porc= missing_by_row_2/data['ambientes_cat'].isna().sum()*100\n",
    "pareto=missing_by_row_2_porc.values\n",
    "acum=[]\n",
    "val_acum=0\n",
    "for i in missing_by_row_2_porc:\n",
    "    val_acum= val_acum+i\n",
    "    acum.append(val_acum)\n",
    "pareto=acum\n",
    "pareto\n",
    "# print(data['municipio'].unique().shape)\n",
    "\n",
    "# #Revisamos la distribución de los nulos por municipio\n",
    "fig=plt.figure()\n",
    "ax= fig.add_subplot(1,1,1)\n",
    "ax.set_title('Pareto Municipios')\n",
    "ax.bar(missing_by_row_2.index, missing_by_row_2, color=\"C0\")\n",
    "ax2=ax.twinx()\n",
    "ax2.plot(missing_by_row_2.index,pareto,color=\"C1\",marker=\"D\",ms=5)\n",
    "# ax2.yaxis.set_major_formatter(PercentFormatter(2))\n",
    "ax.tick_params(axis=\"y\", colors=\"C0\")\n",
    "ax2.tick_params(axis=\"y\", colors=\"C1\")\n",
    "ax.set_xticklabels(missing_by_row_2.index, rotation=90)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agrupamos los registros donde hay nulos (solo para explicar que no tiene impacto la eliminación de los registros)\n",
    "pd.options.display.max_rows = None\n",
    "data_nulos.groupby([\"tipo\"])[\"municipio\"].value_counts().sort_values(ascending=False)\n",
    "#vemos que los nan están distribuidos equitativamente y no están concentrados en una mismo municipio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Los elimino \n",
    "data.dropna(subset=['ambientes_cat'], inplace=True)\n",
    "print(data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()\n",
    "#existen datos que no permiten ver los estadísticos ya que hay valores de 0 en sup_m2_total e inf en precio_usd_por_m2: eliminarlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminamos del dataset los registros de sup_m2_total con valores de cero\n",
    "data.drop(data[(data[\"sup_m2_total\"] ==0)].index, inplace=True ,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realizamos una descripción estadística del dataset\n",
    "data.describe()\n",
    "#Puede observarse mejor los estadisticos media, desv estandar y los minimos y maximos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graficamos las provincias y municipios que contengan un valor mínimo de 500 registros por municipio (para una mejor visualización)\n",
    "limite = 500\n",
    "data = data.copy().groupby(['municipio']).filter(lambda grp: grp.shape[0] > limite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig= plt.subplots(figsize=(20,20),constrained_layout=True)\n",
    "grid = gridspec.GridSpec(2, 1, height_ratios=[1, 3])\n",
    "\n",
    "ax1=plt.subplot(grid[0])\n",
    "sns.countplot(data=data,y=\"provincia\",order=data[\"provincia\"].value_counts().index ,ax=ax1,color=\"g\")\n",
    "\n",
    "ax1.set_yticklabels(ax1.get_yticklabels(),fontsize=\"medium\")\n",
    "ax1.set_title(\"Distribucion de registros segun la provincia\", fontsize= 'large')\n",
    "\n",
    "ax2=plt.subplot(grid[1])\n",
    "sns.countplot(data=data,x=\"municipio\",order=data[\"municipio\"].value_counts().index,ax=ax2,color=\"b\")\n",
    "\n",
    "\n",
    "ax2.set_title(\"Distribucion de registros segun los municipios\", fontsize= 'large')\n",
    "ax2.set_xticklabels(ax2.get_xticklabels(),rotation=90,ha=\"right\")\n",
    "plt.xticks(fontsize= 10)\n",
    "plt.yticks(fontsize= 10)\n",
    "ax1.grid()\n",
    "ax2.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La mayor cantidad de registros están Capital Federal para los barrios de Palermo, Belgrano, Caballito.\n",
    "Consideraremos Capital Federal para la evaluación de los modelos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Revisamos la distribución de registros por tipo de inmueble\n",
    "plt.figure(figsize=(5,3))\n",
    "\n",
    "plt.gca().yaxis.set_major_formatter(ScalarFormatter())\n",
    "ax = sns.countplot(data = data, x = \"tipo\")\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=40,ha=\"right\")\n",
    "plt.show()\n",
    "\n",
    "#Apartamentos tiene la mayoría de los datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apartamentos puede ser una buena eleccion para la evaluacion de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#armamos un dataset nuevo seleccionando capital federal y apartamentos\n",
    "data=data.copy()\n",
    "condicion_provincia= data[\"provincia\"]==\"Capital Federal\"\n",
    "condicion_tipo= data[\"tipo\"]== 'apartment'\n",
    "condicion_compuesta= condicion_provincia&condicion_tipo\n",
    "data = data[condicion_compuesta]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlación entre la variables del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos la correlación entre las variables \n",
    "data_corr = data.corr()\n",
    "#graficamos\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.heatmap(data_corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "plt.title(\"Correlación entre variables\")\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De este cuadro podemos detectar una correlación significativa entre:\n",
    "*precio_usd y sup_m2_total\n",
    "*precio_usd y ambientes_cat_code\n",
    "#precio_usd y lat\n",
    "variables que utilizaremos para las predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analizamos la correlación entre cada una de las variables.\n",
    "figz= plt.figure()\n",
    "mask_cols= [\"sup_m2_total\",\"precio_usd\",\"precio_usd_por_m2\", \"ambientes_cat\", \"municipio_cat_code\", \"ambientes_cat_code\",\"lat\"]\n",
    "graph=sns.pairplot(data[mask_cols],hue=\"sup_m2_total\")\n",
    "graph.fig.set_size_inches(20,10)\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos los siguientes gráficos para visualizar mejor (zoom) las relaciones- En primera medida analizamos metros totales con precio en dolares\n",
    "g = sns.FacetGrid(data, col=\"tipo\")\n",
    "g.map(sns.scatterplot, \"sup_m2_total\", \"precio_usd\", alpha=.5)\n",
    "g.add_legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(data, col=\"tipo\")\n",
    "g.map(sns.scatterplot, \"sup_m2_total\", \"precio_usd_por_m2\", alpha=.5)\n",
    "g.add_legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De estos dos graficos vemos mejor relacion entre variables se enuentra entre sup_m2_total y precio_usd por lo cual utilizaremos estas dos features para predecir"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ademas se puede detectar un outlier que podria impactar sobre las predicciones en la variable Superficie para valores mayores a 965m2 y uno para precios 4x10e6. los cuales eliminaremos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detectamos el valor maximo de superficie total\n",
    "data[\"sup_m2_total\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminamos los outliers\n",
    "data.drop(data[(data[\"sup_m2_total\"]>=965)].index, inplace=True ,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corroboramos que se eliminó el outlier de superficie\n",
    "data[\"sup_m2_total\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corroboramos que se eliminó el outlier de superficie\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminamos outliers para valores de propiedades mayores a 4M usd\n",
    "outliers_precios= data[\"precio_usd\"]>=4000000\n",
    "data.drop(data[outliers_precios].index, inplace=True ,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corroboro que elimino los outliers\n",
    "data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusiones del análisis de variables predictoras y target:\n",
    "- La mayor cantidad de registros están Capital Federal.\n",
    "- Utilizaremos departamentos como el tipo de inmueble a modelar por contener una mayor cantidad de datos\n",
    "- Consideraremos como variables predictora Superficie total y variable objetivo precio usd por su alta correlación, y su distribución. Luego evaluaremos el impacto de las variables de ubicación y cantidad de ambientes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión lineal simple"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizaremos la relacion existente entre la variable objetivo precio total en dolares y su feature la superficie total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparamos la matriz de features y target\n",
    "X = data[['sup_m2_total']]\n",
    "y = data['precio_usd']\n",
    "\n",
    "# Instanciamos el modelo.\n",
    "lm = linear_model.LinearRegression()\n",
    "\n",
    "# Dividimos el dataset en train y test\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ajustamos el modelo a los datos de entrenamiento\n",
    "model = lm.fit(Xtrain, ytrain)\n",
    "\n",
    "# Predecimos etiquetas para datos desconocidos.\n",
    "y_pred = lm.predict(Xtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimimos el intercepto y los coeficientes como atributos del objeto entrenado.\n",
    "print ('Intercepto =', ' ', model.intercept_)\n",
    "print ('b_sup_m2_total=', ' ', model.coef_)\n",
    "# imprimimos la métrica que mide la bondad de ajusto del modelo. En este caso el R2.\n",
    "print(\"R2_train: \", model.score(Xtrain, ytrain))\n",
    "print ('R2_test=','', metrics.r2_score(ytest, y_pred))\n",
    "print ('MSE:', metrics.mean_squared_error(ytest, y_pred))\n",
    "print ('RMSE:', np.sqrt(metrics.mean_squared_error(ytest, y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos el modelo re regresion del modelo con train_test_split\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(Xtest,y_pred,color=\"red\",label=\"Predict line\")\n",
    "plt.scatter(X,y)\n",
    "plt.xlabel(\"Superficie m2 total\")\n",
    "plt.ylabel(\"Precio usd\")\n",
    "plt.title('Modelo VS Precios Reales')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resumen de los parametros estadisticos determinados:\n",
    "\n",
    "El valor inicial de las propiedades es de 25380 u$s, e incrementa 3480 u$s por metro cuadrado de superficie que tiene el departamento en Capital Federal.\n",
    "\n",
    "R2 mide lo bien que un modelo de regresión se ajusta a los datos reales. En otras palabras, se trata de una medida de la precisión general del modelo. vemos que nuestro modelo tiene una precisión del 67% con los datos de testeos. O sea, que el 67% de los datos de precio usd es predicha por la variable superficie m2 total"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión lineal múltiple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregamos a la correlacion las variables latitud y longitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignamos las variables predictoras\n",
    "X = data[['lon','lat', 'sup_m2_total']]\n",
    "y = data['precio_usd']\n",
    "\n",
    "# Normalizamos los datos\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "Xscaler = scaler.fit_transform(X)\n",
    "\n",
    "# Dividimos en train y test\n",
    "Xtrain_regmul, Xtest_regmul, ytrain_regmul, ytest_regmul = train_test_split(Xscaler, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instanciamos el modelo y lo entrenamos\n",
    "lr= linear_model.LinearRegression()\n",
    "model=lr.fit(Xtrain_regmul,ytrain_regmul)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos etiquetas para datos desconocidos.\n",
    "y_pred_regmul = lr.predict(Xtest_regmul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos los coeficientes \n",
    "print('Coeficientes: ', lr.coef_)\n",
    "print('Intercepto: ', lr.intercept_)\n",
    "print(\"R2_train: \", model.score(Xtrain_regmul,ytrain_regmul))\n",
    "print ('R2_test:', metrics.r2_score(ytest_regmul, y_pred_regmul))\n",
    "print ('MSE:', metrics.mean_squared_error(ytest_regmul, y_pred_regmul))\n",
    "print ('RMSE:', np.sqrt(metrics.mean_squared_error(ytest_regmul, y_pred_regmul)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vemos que al agregar a la correlación las variables de ubicación (lon y lat) el modelo de predicción mejora en 0.02%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_simple= np.sqrt(metrics.mean_squared_error(ytest, y_pred))\n",
    "rmse_multiple= np.sqrt(metrics.mean_squared_error(ytest_regmul, y_pred_regmul))\n",
    "print(rmse_simple)\n",
    "print(rmse_multiple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Diferencia porcentual entre el rmse de la regresión simple y la regresión múltiple: ', ((rmse_multiple - rmse_simple)/rmse_simple)*100)\n",
    "print('Diferencia absoluta entre el rmse de la regresión simple y la regresión múltiple: ', rmse_multiple - rmse_simple)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con estas lineas podemos comprobar que al agregar dos variables adicionales, el modelo predice mejor, disminuyendo el error cuadratico medio en un 2%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelamos con statsmodels\n",
    "\n",
    "X_train_sm = sm.add_constant(Xtrain_regmul)\n",
    "\n",
    "model = sm.OLS(ytrain_regmul, X_train_sm).fit()\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando la regresión multiple sencilla con la regresión OLS podemos observar como OLS nos permite validar la significancia de los datos obtenidos. Vemos con los p values para las variables latitud y longitud son menores que el nivel de significancia por lo cual estas variables están explicando o tienen valor de predicción sobre el valor de nuestra variable objetivo precio en dólares.\n",
    "\n",
    "Como vimos en los puntos anteriores el agregar estas dos variables mejora el modelo de predicción."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularización ridge y lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables predictoras: latitud, longitud y superficie total\n",
    "\n",
    "Variable objetivo: precio en usd\n",
    "\n",
    "Volvemos a presentar las metricas obtenidas en la regresión multiple con OLS para las variables mencionadas para comparar con las metricas obtenidas en Lasso y Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probamos con regularización ridge\n",
    "lm_ridge = linear_model.RidgeCV(alphas=np.logspace(-10, 3, 200))\n",
    "\n",
    "model_ridge = lm_ridge.fit(Xtrain_regmul, ytrain_regmul)\n",
    "\n",
    "print ('Modelo Ridge:')\n",
    "print('hiperparametro alpha: ', model_ridge.alpha_)\n",
    "print('coeficientes ajustados: ', model_ridge.coef_)\n",
    "print('intercepto: ', model_ridge.intercept_)\n",
    "print('R2 train: ', model_ridge.score(Xtrain_regmul, ytrain_regmul))\n",
    "print('R2 test: ', model_ridge.score(Xtest_regmul, ytest_regmul))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probamos con regularización lasso\n",
    "\n",
    "lm_lasso = linear_model.LassoCV(alphas=np.logspace(-10, 3, 200), cv=5, tol=0.01)\n",
    "\n",
    "model_lasso = lm_lasso.fit(Xtrain_regmul, ytrain_regmul)\n",
    "\n",
    "print ('Modelo Lasso:')\n",
    "print('hiperparametro alpha : ', model_lasso.alpha_)\n",
    "print('coeficientes ajustados: ', model_lasso.coef_)\n",
    "print('intercepto: ', model_lasso.intercept_)\n",
    "print('R2 train: ', model_lasso.score(Xtrain_regmul, ytrain_regmul))\n",
    "print('R2 test: ', model_lasso.score(Xtest_regmul, ytest_regmul))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que ambos modelos de regularización dan igual R2 que el modelo de regresión lineal multiple, entendiendo que el modelo de regresion lineal multiple no tenia overfitting por corregir.\n",
    "\n",
    "Lasso disminuye los valores betas de ubicacion (lon y lat) y da mas peso a superficie, respecto a ridge, entendiendo de ello que superficie es una variable mas explicativa del peso usd."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Por último, analizaremos el impacto de la variables ambientes en la predicción de la variable precio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos las variables dummies para la variable categórica de ambientes\n",
    "data_ambientes_dummies = pd.get_dummies(data, columns=['ambientes_cat'], drop_first=True)\n",
    "print(data_ambientes_dummies.shape)\n",
    "data_ambientes_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignamos las variables predictoras\n",
    "\n",
    "X_cat = data_ambientes_dummies [['ambientes_cat_1', 'ambientes_cat_2', 'ambientes_cat_3', 'ambientes_cat_4 o mas','sup_m2_total']]\n",
    "y = data_ambientes_dummies ['precio_usd']\n",
    "\n",
    "# Normalizamos los datos\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_cat)\n",
    "X_cat = scaler.transform(X_cat)\n",
    "# X_cat\n",
    "\n",
    "# Dividimos en train y test\n",
    "X_train_cat, X_test_cat, y_train_cat, y_test_cat = train_test_split(X_cat, y, test_size=0.2, random_state=42)\n",
    "#y_test_cat\n",
    "\n",
    "# Instanciamos el modelo y lo entrenamos\n",
    "lr_cat = linear_model.LinearRegression()\n",
    "lr_cat.fit(X_train_cat, y_train_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelamos con statsmodels\n",
    "\n",
    "X_train_sm_2 = sm.add_constant(X_train_cat)\n",
    "model_stats = sm.OLS(y_train_cat, X_train_sm_2).fit()\n",
    "\n",
    "print(model_stats.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probamos con regularización ridge\n",
    "\n",
    "lm_ridge_2 = linear_model.RidgeCV(alphas=np.logspace(-6, 6, 13, 20,30))\n",
    "\n",
    "model_ridge_2 = lm_ridge_2.fit(X_train_cat, y_train_cat)\n",
    "\n",
    "print(lm_ridge_2.alpha_)\n",
    "print(lm_ridge_2.coef_)\n",
    "print(model_ridge_2.score(X_test_cat, y_test_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probamos con regularización lasso\n",
    "\n",
    "lm_lasso_2 = linear_model.LassoCV(alphas=np.logspace(-6, 6, 13,20,30), cv=5, tol=0.1)\n",
    "\n",
    "model_lasso_2 = lm_lasso_2.fit(X_train_cat, y_train_cat)\n",
    "\n",
    "print(lm_lasso_2.alpha_)\n",
    "print(lm_lasso_2.coef_)\n",
    "print(model_lasso_2.score(X_test_cat, y_test_cat))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al modelar las categorias ambientes obtenemos:\n",
    "\n",
    "- OLS: Para un nivel de confianza de 0.05, los p-value del modelo para las variables ambientes (1 a 2 ambientes) son mucho mayores al nivel de confianza por lo que se puede inferir que no tiene correlación con la variable objetivo, para 3 o mas de 4 ambientes y superficie vemos que existe correlación. F-test es mucho mayor que 0,05 por lo que podemos indicar que el modelo no es estadísticamente significativo y que por tanto las variables independientes no explican la variable dependiente. el R2 e menor que cuando no se tienen las varaibles agregadas, motivo por le cual, se podemos decir que estas variables no impactan positivamente sobre el modelo de predicción.\n",
    "\n",
    "- Ridge:vemos que la influencia sobre el modelo de los predictores ambientes están muy poco relacionados con la variable respuesta por lo que los vemos disminuidos.\n",
    "\n",
    "- Lasso: vemos que la influencia sobre el modelo de los predictores ambientes están muy poco relacionados con la variable respuesta por lo que los vemos disminuidos.  La mayor respuesta para explicar el precio usd de las propiedades es la superficie total"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ad4b00cfa812d91f92fb5dc88aa637f6cffee5ca8b01c2f389043adc33b2f6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
